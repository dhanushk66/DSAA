{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "616a2448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Using for cleaning and Pre-Processing\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "import spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "# To generate embedding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS,Phraser\n",
    "from gensim.models import Word2Vec, KeyedVectors #To load the model\n",
    "from cleantext import clean\n",
    "#Visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Calibri\"\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from preprocesss import preprocess_batch\n",
    "#To check for performance\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from keybert import KeyBERT\n",
    "import torch\n",
    "from pygtrie import CharTrie\n",
    "from collections import Counter\n",
    "stopword=list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "482f1524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Dhanush66/AntismetisimLargedata-finetuned-MLM were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at Dhanush66/AntismetisimLargedata-finetuned-MLM and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('Dhanush66/AntismetisimLargedata-finetuned-MLM')\n",
    "model = BertModel.from_pretrained('Dhanush66/AntismetisimLargedata-finetuned-MLM')\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "pa='/Users/dhanushkikkisetti/Documents/Research Assistant/right_left_finetunemodel'\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#model=BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5763bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cabal', 'Cosmopolitan Elite', 'Cultural Marxism', 'Deicide',\n",
       "       'The Goyim Know', 'Holocough', 'Jewish Capitalist',\n",
       "       'Jewish Communist', 'Jew Down', 'Jewish Lobby', 'New World Order',\n",
       "       'Not the Real Jews', 'Rothschild', 'Soros', 'Zionist/Zio',\n",
       "       'Zionist Occupied Government', nan], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/Raza_data/Unmasking Antisemitism SRI Data Set - Reporting Layer.csv\")\n",
    "data=data[['Term or Phrase','Post Text']]\n",
    "data['Term or Phrase'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57721c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b537a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary=['cabal','cosmopolitan elite','cultural marxism','deicide','holocough','jewish capitalist','the goyim know',\n",
    "           'jewish communist','jewish lobby','new world order','rothschild', 'soros','zionist',\n",
    "         'zionist occupied government','jew down','not the real jews'] \n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                                \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "716c3369",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[-data[\"Post Text\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19cebcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lematizer=WordNetLemmatizer()\n",
    "def lematize(text):\n",
    "    text=text.split()\n",
    "    lema=[]\n",
    "    for i in text:\n",
    "        lema.append(lematizer.lemmatize(i))\n",
    "    return (\" \".join(lema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "790551aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean']=data['Post Text'].apply(lambda x:x.lower())\n",
    "#removing the links:\n",
    "data['clean']=data['clean'].apply(lambda x:re.sub(r\"http\\S+\",\"\",str(x)))\n",
    "data['clean']=data['clean'].apply(lambda x:x.translate(str.maketrans(\"\",\"\",string.punctuation)))\n",
    "#Getting the lematised text to get the original form of the word\n",
    "data['lematize']=data['clean'].apply(lambda x:lematize(x))\n",
    "#data['clean']=data['clean'].apply(lambda x:x.translate(str.maketrans(\"\",\"\",string.punctuation)))\n",
    "uncleaned_texts=list(data[\"clean\"])\n",
    "uncleaned_lematised_text=list(data['lematize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1ab0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms=['access biden','access computers','deep state','dollar sent','every dollar','nancy pelosi','voting machines','world economic forum',\n",
    "      'arrested made','bless tate','enemies humanity','every member','extinct deep','god bless','humanity satanic','instead every','member obiden',\n",
    "      'needs extinct','new world order','poor souls','socialist party','souls murdered','started zionist','tate arrested','rootless cosmopolitan',\n",
    "'frankfurt school','early part','found early','marxism found',\n",
    "'origins political',\n",
    "'commit decide',\n",
    "'goyim know',\n",
    "'know shut',\n",
    "'shut goyim',\n",
    "'know goyim',\n",
    "'know vey',\n",
    "'vey goyim',\n",
    "'know kek',\n",
    "'shlomo goyim',\n",
    "'crumble shit',\n",
    "'done goyim',\n",
    "'kek shut',\n",
    "'250k let',\n",
    "'deal already',\n",
    "'done deal',\n",
    "'goyim shlomo',\n",
    "'capitalist intellectuals',\n",
    "'capitalist system',\n",
    "'communist takeover',\n",
    "'communist coup',\n",
    "'coup attempt',\n",
    "'chinese without',\n",
    "'communist criminals',\n",
    "'communist party',\n",
    "'communist pedophiles',\n",
    "'communist propaganda',\n",
    "'communist rule',\n",
    "'failed communist',\n",
    "'kpd communist',\n",
    "'reality ashkenazi',\n",
    "'takeover communist',\n",
    "'without putting',\n",
    "'2004 directed',\n",
    "'back 2004',\n",
    "'big oil',\n",
    "'burning copy',\n",
    "'cartels send',\n",
    "'control united',\n",
    "'copy holy',\n",
    "'crossed swords',\n",
    "'gaza terror',\n",
    "'holy quran',\n",
    "'israel sanction',\n",
    "'send israel',\n",
    "'terror groups',\n",
    "'united states',\n",
    "'disposable small',\n",
    "'small cog',\n",
    "'also known',\n",
    "'back better',\n",
    "'forum declares',\n",
    "'ild back',\n",
    "'job read',\n",
    "'machine job',\n",
    "'order agenda',\n",
    "'order lay',\n",
    "'order machine',\n",
    "'black tribes',\n",
    "'mike tyson',\n",
    "'created israel',\n",
    "'focused like',\n",
    "'gate redpill',\n",
    "'khazarian cabal',\n",
    "'khazarian mafia',\n",
    "'klaus schwab',\n",
    "'mafia minions',\n",
    "'order agenda',\n",
    "'owe money',\n",
    "'owns runs',\n",
    "'pay therefore',\n",
    "'redpill world',\n",
    "'runs created',\n",
    "'sorry owe',\n",
    "'state cabal',\n",
    "'trillionaire jacob',\n",
    "'zionist occupied government',\n",
    "'occupied government',\n",
    "'space time',\n",
    "'time portal',\n",
    "'time information',\n",
    "'blood type',\n",
    "'interfere behalf',\n",
    "'time travel',\n",
    "'advanced technology',\n",
    "'caves space',\n",
    "'children including',\n",
    "'etc names',\n",
    "'occupation government',\n",
    "'spare one',\n",
    "'travel agents',\n",
    "'agent names',\n",
    "'cave accesses',\n",
    "'caves report',\n",
    "'government judeocra',\n",
    "'latin brown',\n",
    "'media organizations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1820a57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40d67b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_terms=[]\n",
    "\n",
    "for t in terms:\n",
    "    for text in uncleaned_texts:\n",
    "        if t in text:\n",
    "            new_terms.append(t)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aed73372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep state',\n",
       " 'nancy pelosi',\n",
       " 'voting machines',\n",
       " 'world economic forum',\n",
       " 'bless tate',\n",
       " 'every member',\n",
       " 'god bless',\n",
       " 'new world order',\n",
       " 'poor souls',\n",
       " 'socialist party',\n",
       " 'tate arrested',\n",
       " 'rootless cosmopolitan',\n",
       " 'frankfurt school',\n",
       " 'early part',\n",
       " 'goyim know',\n",
       " 'know shut',\n",
       " 'deal already',\n",
       " 'done deal',\n",
       " 'capitalist intellectuals',\n",
       " 'capitalist system',\n",
       " 'communist takeover',\n",
       " 'communist coup',\n",
       " 'coup attempt',\n",
       " 'chinese without',\n",
       " 'communist criminals',\n",
       " 'communist party',\n",
       " 'communist pedophiles',\n",
       " 'communist propaganda',\n",
       " 'communist rule',\n",
       " 'failed communist',\n",
       " 'kpd communist',\n",
       " 'without putting',\n",
       " 'big oil',\n",
       " 'cartels send',\n",
       " 'crossed swords',\n",
       " 'gaza terror',\n",
       " 'holy quran',\n",
       " 'israel sanction',\n",
       " 'terror groups',\n",
       " 'united states',\n",
       " 'small cog',\n",
       " 'also known',\n",
       " 'back better',\n",
       " 'order machine',\n",
       " 'black tribes',\n",
       " 'mike tyson',\n",
       " 'created israel',\n",
       " 'focused like',\n",
       " 'khazarian cabal',\n",
       " 'khazarian mafia',\n",
       " 'klaus schwab',\n",
       " 'mafia minions',\n",
       " 'owns runs',\n",
       " 'pay therefore',\n",
       " 'state cabal',\n",
       " 'trillionaire jacob',\n",
       " 'zionist occupied government',\n",
       " 'occupied government',\n",
       " 'space time',\n",
       " 'time portal',\n",
       " 'time information',\n",
       " 'blood type',\n",
       " 'time travel',\n",
       " 'advanced technology',\n",
       " 'caves space',\n",
       " 'children including',\n",
       " 'occupation government',\n",
       " 'travel agents',\n",
       " 'agent names',\n",
       " 'cave accesses',\n",
       " 'latin brown',\n",
       " 'media organizations']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50ffa443",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_glossary=[]\n",
    "for term in glossary:\n",
    "    if len(term.split(\" \"))==1:\n",
    "        new_glossary.append(term)\n",
    "    elif len(term.split(\" \"))==2:\n",
    "        new_glossary.append(term.split()[0])\n",
    "        new_glossary.append(term.split()[1])\n",
    "    else:\n",
    "        terms=list(zip(term.split()[:-1],term.split()[1:]))\n",
    "        pairs=[' '.join(i)  for i in terms]\n",
    "        pairs.append(' '.join([term.split()[0],term.split()[-1]]))\n",
    "        new_glossary+=pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6588a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in new_glossary:\n",
    "    for t in new_terms:\n",
    "        if g in t:\n",
    "            new_terms.remove(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6e2159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_terms.remove(\"early part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3dfc0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_context_words_bigram(sentence, target_bigram, num_words_before, num_words_after):\n",
    "    words = sentence.split()\n",
    "    context_words = []\n",
    "    if len(target_bigram.split())==4:\n",
    "        for i in range(len(words)-3):\n",
    "            fourgram=\" \".join([words[i],words[i+1],words[i+2],words[i+3]])\n",
    "            if fourgram==target_bigram:\n",
    "                start_index = max(0, i - num_words_before)\n",
    "                end_index = min(len(words), i + num_words_after + 4)\n",
    "                context_words.append(words[start_index:end_index])            \n",
    "    elif len(target_bigram.split())==3:\n",
    "        for i in range(len(words) - 2):  # Loop through pairs of consecutive words\n",
    "            trigram=\" \".join([words[i],words[i+1],words[i+2]])\n",
    "            if trigram == target_bigram: \n",
    "                start_index = max(0, i - num_words_before)\n",
    "                end_index = min(len(words), i + num_words_after + 3)\n",
    "                context_words.append(words[start_index:end_index])\n",
    "    else:\n",
    "        for i in range(len(words) - 1):  # Loop through pairs of consecutive words\n",
    "            bigram = \" \".join([words[i], words[i + 1]])\n",
    "            if bigram == target_bigram or words[i]==target_bigram:\n",
    "                start_index = max(0, i - num_words_before)\n",
    "                end_index = min(len(words), i + num_words_after + 2)\n",
    "                context_words.append(words[start_index:end_index])\n",
    "\n",
    "    return [\" \".join(i) for i in context_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae2c0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary=['cabal','cultural marxism','deicide','holocough','jewish capitalist','the goyim know',\n",
    "           'jewish communist','jewish lobby','new world order','rothschild', 'soros','zionist',\n",
    "         'zionist occupied government','not the real jews'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ad0c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "new_text_unclean=[]\n",
    "for text in uncleaned_texts:\n",
    "    t=\"[CLS] \"+text+\" [SEP]\"\n",
    "    text_tokenize=tokenizer.tokenize(t)\n",
    "    if len(text_tokenize)>512:\n",
    "        chunks=len(text_tokenize)//512\n",
    "        chunk_size=len(text.split())//(chunks+1)\n",
    "        for i in range(chunks+1):\n",
    "            extracted_text=\" \".join(text.split(\" \")[i*chunk_size:(i+1)*chunk_size])\n",
    "            new_text_unclean.append(extracted_text)\n",
    "    else:\n",
    "        new_text_unclean.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "13cb875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression=glossary+new_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e7c3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings considering complete sentence and use surrounding words for embeddings\n",
    "def extract_embeddings(Posts:list[str],Expression:list[str],Range:int):\n",
    "    embed_dict={i:[] for i in Expression}\n",
    "    for post in Posts:\n",
    "        t=\"[CLS] \"+post+\" [SEP]\"\n",
    "        text_tokenize=tokenizer.tokenize(t)\n",
    "        if len(text_tokenize)<512:\n",
    "            tensor_input_ids=torch.tensor([tokenizer.convert_tokens_to_ids(text_tokenize)])\n",
    "            tensor_segment_ids= torch.tensor([[1]*len(text_tokenize)])\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                outputs=model(tensor_input_ids,tensor_segment_ids)\n",
    "            token_embeddings = torch.squeeze(outputs[0])\n",
    "            for term in Expression:\n",
    "                if term in post:\n",
    "                    sent=extract_context_words_bigram(sentence=post,target_bigram=term,num_words_before=Range,num_words_after=Range)\n",
    "                    for t in sent:\n",
    "                        sent_tokenize=tokenizer.tokenize(t)\n",
    "                        token_index=[index for index,token in enumerate(text_tokenize) if token in sent_tokenize]\n",
    "                        sent_embed=[]\n",
    "                        for index in token_index:\n",
    "                            sent_embed.append(token_embeddings[index])\n",
    "                        if sent_embed:\n",
    "                            embed=torch.mean(torch.stack(sent_embed),dim=0)\n",
    "                            embed_dict[term].append(embed)\n",
    "    return embed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b9b48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "impembeddings=extract_embeddings(new_text_unclean,expression,Range=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a521f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_embed_terms=[]\n",
    "for i in impembeddings:\n",
    "    if impembeddings[i]==[]:\n",
    "        no_embed_terms.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0674db42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['early part']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_embed_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9260b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "impterm_embeddings={}\n",
    "for term in new_terms:\n",
    "    if term not in no_embed_terms:\n",
    "        impterm_embeddings[term]=torch.mean(torch.stack(impembeddings[term]),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60ecdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary_embeddings={}\n",
    "for term in glossary:\n",
    "    glossary_embeddings[term]=torch.mean(torch.stack(impembeddings[term]),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a670c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "column=[\"Term\"]+glossary+[\"Average\"]\n",
    "bert_similarity_df=pd.DataFrame(columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1a2a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in impterm_embeddings:\n",
    "    score=0\n",
    "    sim_score=[term]\n",
    "    for seed_word in glossary :\n",
    "        s=np.array(torch.cosine_similarity(impterm_embeddings[term].reshape(1,-1),glossary_embeddings[seed_word].reshape(1,-1)))[0]\n",
    "        sim_score.append(s)\n",
    "        score=score+s\n",
    "    sim_score.append(score/len(glossary))\n",
    "    bert_similarity_df.loc[len(bert_similarity_df)]=sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "442f5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=bert_similarity_df['Average'].quantile(0.50)\n",
    "bert_similarity_df['predicted']=bert_similarity_df['Average'].apply(lambda x:1 if x>threshold else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d4214aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8086834464754377"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6576192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bert_similarity_df).to_csv('/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/baseline_results1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e690db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range = 1\n",
      "Range = 2\n",
      "Range = 3\n",
      "Range = 4\n",
      "Range = 5\n",
      "Range = 6\n",
      "Range = 7\n",
      "Range = 8\n",
      "Range = 9\n",
      "Range = 10\n"
     ]
    }
   ],
   "source": [
    "predicted_labels={}\n",
    "column=[\"Term\"]+glossary+[\"Average\"]\n",
    "for r in range(1,11):\n",
    "    print(\"Range = \"+str(r))\n",
    "    impembeddings=extract_embeddings(new_text_unclean,expression,Range=r)\n",
    "    impterm_embeddings={}\n",
    "    for term in new_terms:\n",
    "        impterm_embeddings[term]=torch.mean(torch.stack(impembeddings[term]),dim=0)\n",
    "    glossary_embeddings={}\n",
    "    for term in glossary:\n",
    "        glossary_embeddings[term]=torch.mean(torch.stack(impembeddings[term]),dim=0)\n",
    "    bert_similarity_df=pd.DataFrame(columns=column)\n",
    "    for term in impterm_embeddings:\n",
    "        score=0\n",
    "        sim_score=[term]\n",
    "        for seed_word in glossary :\n",
    "            s=np.array(torch.cosine_similarity(impterm_embeddings[term].reshape(1,-1),glossary_embeddings[seed_word].reshape(1,-1)))[0]\n",
    "            sim_score.append(s)\n",
    "            score=score+s\n",
    "        sim_score.append(score/len(glossary))\n",
    "        bert_similarity_df.loc[len(bert_similarity_df)]=sim_score\n",
    "    threshold=bert_similarity_df['Average'].quantile(0.50)\n",
    "    bert_similarity_df['predicted']=bert_similarity_df['Average'].apply(lambda x:1 if x>threshold else 0)\n",
    "    predicted_labels[r]=bert_similarity_df['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94d58c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame.from_dict(predicted_labels)\n",
    "results['avg']=results.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ae987ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Predicted']=results['avg'].apply(lambda x:1 if x>0.8 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4637e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/baseline_results_1_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c2fc109",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=pd.read_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/baseline_results_1_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acc1fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Accuracy :  0.6551724137931034\n",
      "Precision :  0.7272727272727273\n",
      "Recall  :  0.32\n",
      "F1 Score  :  0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------\")\n",
    "print(\"Accuracy : \",accuracy_score(data_file['Predicted'],data_file['Actual']))\n",
    "print(\"Precision : \",precision_score(data_file['Predicted'],data_file['Actual']))\n",
    "print(\"Recall  : \",recall_score(data_file['Predicted'],data_file['Actual']))\n",
    "print(\"F1 Score  : \",f1_score(data_file['Predicted'],data_file['Actual']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2e9eb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414172699 the great reset will happen next weekjfk and princess diana will come backtrump is still the presidenttrump is speaking like biden because biden will answer to trumps crimes that biden actually didthe cabal will soon be exterminatedgod bless youqtards literally live in an imaginary world\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - -  -\n",
      "articles proving putins role in the great resetglobalization putin  xi working to dugins multipolar eurasian plan global jewishcommunist slavery eastern  western jews in lockstep  kissinger  dugin jewish collapse of the west in full swing plan to annexe all western europe  destroy western civilization in preplanned ww3 deception  sinosoviet scissors strategy explained\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - -  -\n",
      "the biden clown show is useless and weak the goal of this globalist stooge is to destroy the us economy for its entry into the new world ordergreat resetliberal world order global village international world order all the same schitte with a different name\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - -  -\n",
      "all part of the coming digitalcontrolgrid no new cash money the new moneye the one eye money will be cbdc cbdcs all digital money will be the end of human freedom their control system requires the planned phasing out of cash money in case you missed it weareatwar with a darkoccult attempting to impose their new world order great reset\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - -  -\n",
      "407694962 completely shit the bed as administratorstry to rebrand it as a great reset and a new world orderlollmao\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - -  -\n",
      "jesuit joe biden globalist puppet tool of the trillionaire jacob rothschild and his khazarian mafia minions the globalists are being exposed worldwide and the masses are rejecting their great reset now they have intensified their dangerous and desperate tactics to fight back against the serfs and slaves they wish to control a main goal is to depopulate the earth its easier to control less of us\n",
      " \n",
      " biden  bilderbergs idiot destroying entire nation\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - -  -\n",
      "mccarthy to replace biden as us â€œpresidentâ€ while the un prepares to move to laossome tectonic shifts have taken place in geopolitical power structures during the past week the result will be the widely despised avatar â€œjoe bidenâ€ being replaced as us president by house speaker kevin mccarthy pentagon and mi6 sources say also preparations to move un headquarters from new york to laos have begun in earnest cia sources in laos saythese changes are taking place as the main culprits for the present dysfunctional state of the planet gather at davos switzerland for the world economic forum as this report was about to go live cia sources say the head of this organization klaus schwab rothschild klaus schwab would miss the opening of the wef conference in davos today â€œdue to a health issueâ€ this was a disinformation trap designed to destroy the credibility of this newsletter by having him or an avatar appear after we report his absence the wef was unavailable for comment regardless the criminals gathering at davos have lost the battle for the planet earth multiple sources agree we know is that the entire hitlerrockefeller branch of the ruling class has lost power this means descendants of adolph hitler and john rockefeller i including angela merkel hillary clinton barack obama david rockefeller jr etc will be stripped of all power and titles mi6 sources sayto confirm if this is true we need to see the public removal of rockefeller avatar â€œpresident joe bidenâ€ along with the rubber maskwearing phony pope francisthere are signs this is happening in the us a power struggle has resulted in a compromise wherein neither donald trump nor joe biden will be in power the supreme court rejected the brunson case to overthrow the 2020 election because it would have installed donald trump as president the reason is the donald trump who has appeared in public since january of 2020 is a vaccinepushing fraud the real donald trump whose son barron was injured by vaccines was virulently opposed to them this means if the supreme court had reinstated trump then the avatar joe biden who took orders from the rockefellers would have been replaced by a trump avatar who took orders from the rothschildsso serious horsetrading took place in the 15 rounds of votes it took to make kevin mccarthy speaker of the house mccarthy was forced among other things to promise to hold hearings into how the fbi was turned into a malignant force suppressing american patriots latest intelligence we have is that joe biden will be removed along with kamala harris the second in line for the presidency that would make mccarthy president but only as an interim figure who would oversee new and genuine elections in such an election the real donald trump would runthat is why we are now seeing headlines such as this in the corporate propaganda mediaformer clinton adviser david gergen says biden risks being â€˜creamedâ€™ by docs case â€˜very very big dealâ€™ shows they are going to use the â€œdocuments in garageâ€ story instead of child rape and murder or selling the us government out to gangsters in ukraine as the excuse to end the biden farce to reconfirm it is a farce notice how the fake biden doesnâ€™t blink in this video most likely it is cgi dumb show cannot last much longerwe are also seeing a very strong campaign to remove â€œpope francisâ€ that is why we are seeing news reports a plot to remove him â€œbegan in earnestâ€ immediately after pope benedict maledict xvi died on december 31st sudden death on january 10th of the head of the vatican bank cardinal george pell is probably related to this battle pell was an ally of the real pope francis who decried the phony francis as a â€œdisasterâ€ and a â€œcatastropheâ€ in any case p3 sources say the fake francis has been canceling all of his public appearances for days in a row because of â€œa mysterious illnessâ€what we know for sure is that some sort of purge of the highest levels of power has been taking place in recent weeks with the death of top chinese power broker jiang zemin queen elizabeth ii evelyn de rothschild pope benedict etcwe are also hearing this is all related to the fact a new m1 or head of the committee of 300 and controller of the world financial system has been selectedwe have been in contact with this individual who is a european royal you have most likely never heard of this person says â€œm1 simply means monetary one or the global underwriting of the worldâ€™s banksâ€¦ monetary one is simply a legal signatory to all other debt you canâ€™t sign country debt to thin air so it has to end somewhere with someoneâ€the new m1 says the main obstacle to a jubilee and the establishment of a meritocratic future planning agency isâ a â€œstalemate comes from the fifth column inside mi6â€ this group is connected to the illuminati and is upset among other things about the public use of king charles iii as the face of the british monarchy because of his alleged involvement in the murder of princess dianacharles is putting out the following storyâ€œiranian military intelligence  probable cause pakistan isi killing assassinated is in law murdered of dodi fayed the son of the then owner of harrodâ€™s shop in londonâ€¦diana died not as a killing but as a secondary consequence of the assassinated primary because of money laundering linked to arms tradingâ€¦neither her majesty the queen her majestyâ€™s consort prince philip nor i would now add have any hand act or part in thisâ€the source admits â€œmi6 did in fact provide a militarygrade optical device which was of sufficient disablement to cause a road traffic accidentâ€ and that the head of mi6 sir john scarlett â€œis now known to us to have been within a onemile radius of this crime sceneâ€ however the former head of mi6 dr michael van de meer said dianaâ€™s death was an honor killing that took place because she was pregnant with fayedâ€™s twins and was going to convert to islamin any case assuming mi6 acted on its own without the knowledge of any british royal family member if a dispute over this is what is preventing the start of a new financial system and a new age then some sort of workaround is needed apparently prince william does not want to assume the throne in the place of his father so maybe england can have a king harold for the first time since 1066 while the mysterious m1 remains the real power behind the throne this is something for the privy council to decide and the rest of the ruling class will have to go along with their decisionthere is also a very real possibility of a general revolt against the bloodline ruling class in the west the ongoing economic collapse and fallout from the vaccine and pandemic scam make a bloody revolution increasingly likelythe gnostic illuminati are definitely on the warpath the new mi says â€œdavid de rothschild tells me this socalled illuminati have in fact attempted to contact meâ€¦my instagram account is being inundated with various references to very famous people and this is all happening only in the last day or so despite a very strict press ban about cameras or any other attempt to contact me through a back channel so i immediately called in mi6 and the sas as my bodyguardsâ€here is a message we received from the illuminaticardinals inside the vatican are preparing for the removal 33 degree freemasons including the jesuit pope this message is to the world that the 33rd masons jesuits no longer have control at the highest command levels all ds 33 steps gt committee of 300 fortune 500 gt blackrockin what is probably related we have noted that a major fire recently destroyed a masonic center in south west sydney also incite riots and social unrest throughout the western hemisphere jews are also revolting as this statement by jewish freedom fighter henry makow makes clearpope francis is an imposter â€“ a cryptojew km implanted by the wef just in time for the â€œgreat resetâ€ facade that begins 2020 with the covid19 scam he joins his brothers justin trudeau joe biden emmanuel macron jacinda ardern yes a brother and not a sister barack obama and michele obama like jacinda volodymyr zelenskyy tedros ghebreyesus and other homosexuals and fake leaders who easily blackmailed and brought to power by the jews km to destroy christianity and european culturesthe economic collapse in the us and other western countries will lead to further unrest if the new system is not implemented as soon as possible hyperinflation rising interest rates and collapsing markets are all happening at the same timeas this chart shows the housing bubble in the us is so big that it can only be dealt with by a complete reset of the financial system the next chart shows that real wages are falling very very quickly in this chart too the real fall in wages is underestimated since official inflation figures are used which account for around half of real inflation tremendous rise in crime is also leading to a general breakdown in social order particularly in the united states the situation has reached a point where even the groceries in the supermarkets have to be put under lock and key type of situation is not unique to the us in poland elderly people are being forced to steal food from stores to survive while their government continues to tout vaccines to bail out through murder polish intelligence sources saythey note that polish military units revolted last week disobeying government orders to fight the russians in ukrainein hungary 97 of citizens who took part in the national consultations opposed eu sanctions against russia said alexandra sentkiraji a spokeswoman for the hungarian governmentdue to space limitations we will not go into detail about the situation in ukraine this week but recommend this page was heavily attacked for reporting true news about ukraine etc i had to set up a virtual private network to gain access and even that was blocked itâ€™s back now so be sure to check it outin any case the km ruling class is losing control in ukraine and on all other fronts as this collapse takes place the ruling class is locked in a mexican standoff of mutual blackmail as m1 notesâ€œburied in some mountain near zug switzerland is a camp that no doubt has a file on everyone who holds a position of power anywhere above the richest and most powerful in the world sit the cults into which they are all incultated and through various gatherings and practices have been compromised for total control above the cults and behind the scenes km is doing what it has been doing for over a thousand yearsâ€ kmâ€™s attempt to stay in power by killing everyone with either a pandemic or a vaccine is now blowing their minds the vaccine damage is now so extensive that even official bodies like the cdc are forced to admit it the us congress has freed itself and its families and its employees and their families from all the mandates and demands they made of their employers the american people they also freed the employees of the cdc and the officers and employees of the pharmaceutical companies involved in this system the corruption behind this whole campaign is so extensive that most western ruling governments are up to their necks in it only way out of this impasse is the proclamation of a jubilee and a truth and reconciliation process followed by a general amnesty but itâ€™s probably too late for an amnesty for vaccine crimesit is also too late to try to save the current financial system through reforms we note that republicans in the house of representatives plan to resolve the situation by abolishing the internal revenue service irs abolishing the national income tax and replacing it with a national consumption tax with a jubilee and stateissued money as opposed to debt to the km not even an excise tax would be requiredin any case talk of tax reform is like rearranging deckchairs on the titanic as us society has been on the back burner for years this week they will run out of money once again and take their begging cup to china to offer more family heirlooms in exchange for a quick fix with total us debt and unfunded debt approaching 300 trillion the only answer is a complete resetthe situation is urgent because if the west does not get behind the new m1 the russians chinese brics etc will take over with or without western cooperationsources from the white dragon society in laos report that the nonwestern world has started construction of a new un headquarters there and will build its own international architecture they are also preparing their own international financial systemrussian security council secretary nikolai patrushev says the american state is just a â€œcover for a conglomerate of giant corporations that run the country and are trying to dominate the worldâ€ he adds â€œtransnational corporations treat even us presidents as mere figureheads who can be silenced as happened with donald trump republicans and democrats are just two actors in a staging that has nothing to do with democracy hasâ€ permanent representative to the united nations vassily nebenzia said that if peace with the west cannot be achieved through negotiations â€œthen we will carry out our tasks by military meansâ€ only possible hope for the west to remain relevant is if its secret space force finally reveals itself this could happen as this us space force press release suggestsseven nations meet on space securityarlington va afns â€“the department of defense has participated in the annual cspo combined space operations initiativeâ€¦ with representatives from australia canada france germany new zealand the united kingdom and the united states with a focus on promoting cooperation and the exchange of information on space security issues that in mind here are the latest spacethemed images news release from the us national geographic survey shows an earthquake with an epicenter at a negative depth of 06 kilometers which apparently means there was some kind of explosion in space over silicon valley please correct us if weâ€™re wrong about that \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - -  -\n"
     ]
    }
   ],
   "source": [
    "for text in uncleaned_texts:\n",
    "    if \"great reset\" in text:\n",
    "        print(text)\n",
    "        print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - -  -\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79c6cb",
   "metadata": {},
   "source": [
    "### For sentence embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb5dc76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(Posts:list[str],Expression:list[str],rAnge:int):\n",
    "    terms_not_intext=[]\n",
    "    embed_dict={}\n",
    "    sent_dict={i:[] for i in Expression}\n",
    "    for term in Expression:\n",
    "        for post in Posts:\n",
    "            if term in post:\n",
    "                sents=extract_context_words_bigram(sentence=post,target_bigram=term,num_words_before=rAnge,num_words_after=rAnge)\n",
    "                if bool(sents):\n",
    "                    for sent in sents:\n",
    "                        sent_dict[term].append(sent)\n",
    "    for key in sent_dict:\n",
    "        if bool(sent_dict[key]):\n",
    "            sent_tokenize=tokenizer(sent_dict[key],return_tensors='pt',padding=True,max_length=512,truncation=True)\n",
    "            with torch.no_grad():\n",
    "                model_output=model(**sent_tokenize)['pooler_output']\n",
    "                embed_dict[key]=model_output\n",
    "        else:\n",
    "            terms_not_intext.append(key)\n",
    "        \n",
    "    return embed_dict,terms_not_intext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1cbe3eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range = 5\n",
      "Range = 6\n",
      "Range = 7\n",
      "Range = 8\n",
      "Range = 9\n",
      "Range = 10\n",
      "Range = 11\n",
      "Range = 12\n",
      "Range = 13\n",
      "Range = 14\n"
     ]
    }
   ],
   "source": [
    "predicted_labels={}\n",
    "column=[\"Term\"]+glossary+[\"Average\"]\n",
    "for r in range(5,15):\n",
    "    print(\"Range = \"+str(r))\n",
    "    impembeddings,no_term_embed=extract_embeddings(new_text_unclean,expression,rAnge=r)\n",
    "    \n",
    "    impterm_embeddings={}\n",
    "    for term in new_terms:\n",
    "        impterm_embeddings[term]=torch.mean(impembeddings[term],dim=0)\n",
    "    glossary_embeddings={}\n",
    "    for term in glossary:\n",
    "        glossary_embeddings[term]=torch.mean(impembeddings[term],dim=0)\n",
    "    bert_similarity_df=pd.DataFrame(columns=column)\n",
    "    for term in impterm_embeddings:\n",
    "        score=0\n",
    "        sim_score=[term]\n",
    "        for seed_word in glossary :\n",
    "            s=np.array(torch.cosine_similarity(impterm_embeddings[term].reshape(1,-1),glossary_embeddings[seed_word].reshape(1,-1)))[0]\n",
    "            sim_score.append(s)\n",
    "            score=score+s\n",
    "        sim_score.append(score/len(glossary))\n",
    "        bert_similarity_df.loc[len(bert_similarity_df)]=sim_score\n",
    "    threshold=bert_similarity_df['Average'].quantile(0.50)\n",
    "    bert_similarity_df['predicted']=bert_similarity_df['Average'].apply(lambda x:1 if x>threshold else 0)\n",
    "    predicted_labels[r]=bert_similarity_df['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46e81de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame.from_dict(predicted_labels)\n",
    "results['avg']=results.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b1b16f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Predicted']=results['avg'].apply(lambda x:1 if x>0.6 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f7a4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/baseline_sentence_embed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a2d996fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=pd.read_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/baseline_results_1_10.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "37c9a619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Accuracy :  0.7692307692307693\n",
      "Precision :  0.3684210526315789\n",
      "Recall  :  1.0\n",
      "F1 Score  :  0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------\")\n",
    "print(\"Accuracy : \",accuracy_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"Precision : \",precision_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"Recall  : \",recall_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"F1 Score  : \",f1_score(data_file['Actual'],data_file['Predicted']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
