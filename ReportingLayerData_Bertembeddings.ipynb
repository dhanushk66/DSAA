{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5f9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Using for cleaning and Pre-Processing\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "import spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "# Loading transformers library\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel,AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('Dhanush66/AntismetisimLargedata-finetuned-MLM-NEW')\n",
    "model = BertModel.from_pretrained('Dhanush66/AntismetisimLargedata-finetuned-MLM-NEW')\n",
    "# To generate embedding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS,Phraser\n",
    "from gensim.models import Word2Vec, KeyedVectors #To load the model\n",
    "from cleantext import clean\n",
    "#Visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Calibri\"\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from preprocesss import preprocess_batch\n",
    "#To check for performance\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keybert import KeyBERT\n",
    "from pygtrie import CharTrie\n",
    "from collections import Counter\n",
    "stopword=list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a690334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"Unmasking Antisemitism SRI Data Set - Reporting Layer.csv\")\n",
    "data=data[['Term or Phrase','Post Text']]\n",
    "data['Term or Phrase'].unique()\n",
    "\n",
    "#Get the number of rows\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7c1a917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the duplicates\n",
    "data=data.drop_duplicates()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0d8921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary=['cabal','cosmopolitan elite','cultural marxism','deicide','holocough','jewish capitalist','the goyim know',\n",
    "           'jewish communist','jewish lobby','new world order','rothschild', 'soros','zionist',\n",
    "         'zionist occupied government','jew down','not the real jews'] \n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                                \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a43b2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[-data[\"Post Text\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7c1e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text=data['Post Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fcd12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lematizer=WordNetLemmatizer()\n",
    "def lematize(text):\n",
    "    text=text.split()\n",
    "    lema=[]\n",
    "    for i in text:\n",
    "        lema.append(lematizer.lemmatize(i))\n",
    "    return (\" \".join(lema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1163cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean']=data['Post Text'].apply(lambda x:x.lower())\n",
    "#removing the links:\n",
    "data['clean']=data['clean'].apply(lambda x:re.sub(r\"http\\S+\",\"\",str(x)))\n",
    "#Getting the lematised text to get the original form of the word\n",
    "data['lematize']=data['clean'].apply(lambda x:lematize(x))\n",
    "#data['clean']=data['clean'].apply(lambda x:x.translate(str.maketrans(\"\",\"\",string.punctuation)))\n",
    "uncleaned_texts=list(data[\"clean\"])\n",
    "uncleaned_lematised_text=list(data['lematize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135827ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text,postag,stopword,lematizer):\n",
    "    pos_removal=[tag[0] for tag in pos_tag(text.split()) if tag[1] in postag]\n",
    "    return(\" \".join([lematizer.lemmatize(i) for i in pos_removal if i not in stopword]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7625bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "postag=[\"JJ\",'NN','NNS','NNP','VBP']\n",
    "stopword=list(stopwords.words('english'))\n",
    "def preprocess_parallel(sentences, postag, stopword, num_workers):\n",
    "    chunk_size = len(sentences) // num_workers\n",
    "    chunks = [sentences[i:i + chunk_size] for i in range(0, len(sentences)+1, chunk_size)]\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = executor.map(preprocess_batch, chunks, [postag] * num_workers, [stopword] * num_workers)\n",
    "    processed_sentences = [item for sublist in results for item in sublist]\n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a04d0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sentences_parallel = preprocess_parallel(sentences=uncleaned_texts, \n",
    "                                                   postag=postag, stopword=stopword, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4ad17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean\"]=processed_sentences_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9729b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lematize']=data['clean'].apply(lambda x:lematize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "191c605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_text=list(data['Post Text'])\n",
    "\n",
    "lematised_texts=list(data['lematize'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2145a6e",
   "metadata": {},
   "source": [
    "## Finding Important terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e7bf30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emerging(terms):\n",
    "\n",
    "    check=True\n",
    "    while(tqdm(check)):\n",
    "        #For each time step\n",
    "        important_terms={}\n",
    "        text=' '.join(data.clean)\n",
    "        #Generate TF-IDF Matrix\n",
    "        tf_idfvectorizer=TfidfVectorizer(ngram_range=(2,3))\n",
    "        tfidf=tf_idfvectorizer.fit_transform(data.clean)\n",
    "        features=tf_idfvectorizer.get_feature_names_out()\n",
    "        \n",
    "        #Exporting all Bigrams\n",
    "        #pd.DataFrame(features).to_csv(\"Bigrams \"+str(z)+\".csv\",header=['All Bigrams'])\n",
    "        \n",
    "        #Finding Emerging terms/Initializing glossary\n",
    "        emerging_terms=list(set(features).difference(glossary))\n",
    "        emerging_terms_trie = CharTrie()\n",
    "        for term in emerging_terms:\n",
    "            emerging_terms_trie[term] = True\n",
    "\n",
    "                #glossary.append(i)\n",
    "        print(\"started\")\n",
    "        #Finding the index of emerging terms\n",
    "        findex=[i for i, word in enumerate(features) if word in emerging_terms_trie]\n",
    "        \n",
    "        tfidf_highest=tfidf.max(axis=0)\n",
    "        #Finding the highest tf-idf value for all the feature names across all documents\n",
    "        tfidf_values={}\n",
    "        for i in tqdm(findex):\n",
    "            tfidf_values[features[i]]=tfidf_highest.toarray()[0][i]\n",
    "        \n",
    "        tfidf_values=sorted(tfidf_values.items(),key=lambda x:x[1],reverse=True)\n",
    "        print(\"Ended\")\n",
    "        #Exporting Top Tf-idf values with bigrams\n",
    "        \n",
    "        #pd.DataFrame(tfidf_values).to_csv(\"SubtractionBigram-Tfidf \"+str(z)+\".csv\",header  = ['Bigrams','TF-IDF Values'])\n",
    "        #print(tfidf_values[:20])\n",
    "    \n",
    "        #Extracting bigrams after TF-IDF threshold cut off\n",
    "        a=sum(j for i, j in tfidf_values)\n",
    "        print(\"Threshold \",a/len(tfidf_values))\n",
    "        th=a/len(tfidf_values)\n",
    "        final_tfidf={}\n",
    "        for i in tfidf_values:\n",
    "            if i[1]>th and len(i[0])<25:\n",
    "                final_tfidf[i[0]]=i[1]\n",
    "        #Exporting Tf-idf values above threshold\n",
    "        #pd.DataFrame.from_dict(data=final_tfidf, orient='index').to_csv(\"Bigram_threshold \"+str(z)+\".csv\",index_label='Bigrams',header  = ['TF-IDF Values'])\n",
    "        \n",
    "        #Frequency of words in that window size\n",
    "        words_frequency={}\n",
    "        text1=text.split(\" \")\n",
    "        #pairs=list(zip(text1[:-1],text1[1:]))\n",
    "        #trigram_pairs=list(zip(text1[:-2],text1[1:-1],text1[2:]))\n",
    "        #bigrams=[' '.join(i) for i in pairs]\n",
    "        #trigrams=[\" \".join(i) for i in trigram_pairs]\n",
    "        #bigram_frequency=Counter(bigrams)\n",
    "        #trigram_frequency=Counter(trigrams)\n",
    "        unigram_frequency=Counter(text1)\n",
    "        for word in (final_tfidf.keys()):\n",
    "            words_frequency[word]=unigram_frequency[word]\n",
    "                \n",
    "        words_frequency=sorted(words_frequency.items(),key=lambda x:x[1],reverse=True)\n",
    "        \n",
    "        #Appending terms in Imp terms list\n",
    "        for i in range(terms):\n",
    "            important_terms[words_frequency[i][0]] = words_frequency[i][1]\n",
    "        \n",
    "        \n",
    "        # Exporting Bigrams with frequency\n",
    "        #pd.DataFrame(words_frequency).to_csv(\"Bigram_frequency \"+str(z)+\".csv\",header  = ['Bigrams','Frequency'])\n",
    "        \n",
    "        #Exporting Important terms that is coming from  window\n",
    "        #pd.DataFrame.from_dict(data=important_terms, orient='index').to_csv(\"Important_terms \"+str(z)+\".csv\",index_label='Bigrams',header  = ['Frequency'])\n",
    "\n",
    "        return important_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9b92663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61750/61750 [00:03<00:00, 15488.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended\n",
      "Threshold  0.07511801034902785\n"
     ]
    }
   ],
   "source": [
    "imp_terms=emerging(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daa7a027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new world': 68,\n",
       " 'world order': 42,\n",
       " 'zionist occupied': 32,\n",
       " 'united state': 26,\n",
       " 'goy know': 25,\n",
       " 'george soros': 22,\n",
       " 'blood type': 22,\n",
       " 'vatican ii': 22,\n",
       " 'nostra aetate': 21,\n",
       " 'occupied government': 17,\n",
       " 'human right': 16,\n",
       " 'jesus christ': 15,\n",
       " 'deep state': 13,\n",
       " 'zionist reptilian': 12,\n",
       " 'far right': 11,\n",
       " 'white people': 11,\n",
       " 'jewish community': 11,\n",
       " 'fascist white': 11,\n",
       " 'new york': 10,\n",
       " 'including zionist': 10,\n",
       " 'church always': 10,\n",
       " 'un special': 9,\n",
       " 'late 20th': 9,\n",
       " 'space time': 9,\n",
       " 'space time information': 9,\n",
       " 'time information': 9,\n",
       " 'white power': 9,\n",
       " 'african identity': 8,\n",
       " 'zionist jewish': 8,\n",
       " 'moon landing': 8,\n",
       " 'middle east': 8,\n",
       " 'critical race': 8,\n",
       " 'church teaching': 8,\n",
       " 'people color': 8,\n",
       " 'civil right': 8,\n",
       " 'world war': 7,\n",
       " 'old school': 7,\n",
       " 'zionist time': 7,\n",
       " 'special rapporteur': 7,\n",
       " 'un special rapporteur': 7,\n",
       " 'federal reserve': 7,\n",
       " 'white men': 7,\n",
       " 'interfere behalf': 7,\n",
       " 'say jew': 7,\n",
       " 'throw jew': 6,\n",
       " 'get rid': 6,\n",
       " 'need get': 6,\n",
       " 'zionist jew': 6,\n",
       " 'klaus schwab': 6,\n",
       " 'khazarian satanist': 6,\n",
       " 'mel gibson': 6,\n",
       " 'central bank': 6,\n",
       " 'sound like': 6,\n",
       " 'social justice': 6,\n",
       " 'american jew': 6,\n",
       " 'jewish lobby group': 6,\n",
       " 'lobby group': 6,\n",
       " 'published online': 6,\n",
       " 'always taught': 6,\n",
       " 'church always taught': 6,\n",
       " 'communist party': 6,\n",
       " 'ruling class': 6,\n",
       " 'jew well': 5,\n",
       " 'throw jew well': 5,\n",
       " 'real jew': 5,\n",
       " 'go back': 5,\n",
       " 'khazarian mafia': 5,\n",
       " 'white house': 5,\n",
       " 'jewish cabal': 5,\n",
       " 'national socialist': 5,\n",
       " 'destroying nation': 5,\n",
       " 'destroying entire': 5,\n",
       " 'full disclosure': 5,\n",
       " 'state america': 5,\n",
       " 'united state america': 5,\n",
       " 'military operation': 5,\n",
       " 'year ago': 5,\n",
       " 'air traffic': 5,\n",
       " 'public service': 5,\n",
       " 'white american': 5,\n",
       " 'german people': 5,\n",
       " '20th century': 5,\n",
       " 'white race': 5,\n",
       " 'jew accept': 5,\n",
       " 'jew reject': 5,\n",
       " 'organized jewry': 5,\n",
       " 'roy cohn': 4,\n",
       " 'elite killed': 4,\n",
       " 'hollywood elite': 4,\n",
       " 'hollywood elite killed': 4,\n",
       " 'globalists cabal': 4,\n",
       " 'world economic': 4,\n",
       " 'accursed guilty': 4,\n",
       " 'ethnic foids': 4,\n",
       " 'manhattan new': 4,\n",
       " 'manhattan new york': 4,\n",
       " 'new york city': 4,\n",
       " 'york city': 4,\n",
       " 'cultural marxist': 4,\n",
       " 'name zionist': 4,\n",
       " 'blame slav': 4,\n",
       " 'mayer amschel': 4,\n",
       " 'political correctness': 4,\n",
       " 'interest group': 4,\n",
       " 'african identity black': 4,\n",
       " 'identity black': 4,\n",
       " 'frankfurt school': 4,\n",
       " 'one listening': 4,\n",
       " 'nazi germany': 4,\n",
       " 'coup attempt': 4,\n",
       " 'rothschild family': 4,\n",
       " 'western civilization': 4,\n",
       " 'chairman jewish': 4,\n",
       " 'chairman jewish lobby': 4,\n",
       " 'anti white': 4,\n",
       " 'catholic church': 4,\n",
       " 'meet new': 4,\n",
       " 'million dollar': 4,\n",
       " 'would say': 4,\n",
       " 'jewish elite': 4,\n",
       " 'nancy pelosi': 4,\n",
       " 'de rothschild': 4,\n",
       " 'jeffrey epstein': 4,\n",
       " 'also need': 4,\n",
       " 'grand marshal': 4,\n",
       " 'american lunar': 4,\n",
       " 'crowning achievement': 4,\n",
       " 'took place': 4,\n",
       " 'donald trump': 4,\n",
       " 'financial system': 4,\n",
       " 'intelligence gathering': 4,\n",
       " 'joe biden': 4,\n",
       " 'ancient israelite': 4,\n",
       " 'cancer destroying': 4,\n",
       " 'cancer destroying middle': 4,\n",
       " 'destroying middle': 4,\n",
       " 'destroying middle east': 4,\n",
       " 'twin cancer': 4,\n",
       " 'twin cancer destroying': 4,\n",
       " 'national security': 4,\n",
       " 'social medium': 4,\n",
       " 'air traffic control': 4,\n",
       " 'traffic control': 4,\n",
       " 'american jewish': 4,\n",
       " 'christ cursed': 4,\n",
       " 'special military': 4,\n",
       " 'special military operation': 4,\n",
       " 'mike tyson': 3,\n",
       " 'fema camp': 3,\n",
       " 'cabal need': 3,\n",
       " 'zog zionist occupied': 3,\n",
       " 'pulled wef': 3,\n",
       " 'zog zionist': 3,\n",
       " 'fuck new': 3,\n",
       " 'fuck new world': 3,\n",
       " 'dont let': 3,\n",
       " 'queen story': 3,\n",
       " 'queen story time': 3,\n",
       " 'story time': 3,\n",
       " 'keep getting': 3,\n",
       " 'zionist jewish cabal': 3,\n",
       " 'deep state cabal': 3,\n",
       " 'state cabal': 3,\n",
       " 'jacob rothschild': 3,\n",
       " 'usa get': 3,\n",
       " 'elite killed unborn': 3,\n",
       " 'killed unborn': 3,\n",
       " 'killed unborn child': 3,\n",
       " 'unborn child': 3,\n",
       " 'color revolution': 3,\n",
       " 'jewish people': 3,\n",
       " 'agent embedded': 3,\n",
       " 'end game': 3,\n",
       " 'open society': 3,\n",
       " 'orthodox christian': 3,\n",
       " 'mental illness': 3,\n",
       " 'therefore america': 3,\n",
       " 'rejected christ': 3,\n",
       " 'german christian': 3,\n",
       " 'holy war': 3,\n",
       " 'across video': 3,\n",
       " 'across video must': 3,\n",
       " 'anti white genocide': 3,\n",
       " 'came across': 3,\n",
       " 'came across video': 3,\n",
       " 'video must': 3,\n",
       " 'video must watch': 3,\n",
       " 'destroy america': 3,\n",
       " 'jewish banker': 3,\n",
       " 'entry new': 3,\n",
       " 'entry new world': 3,\n",
       " 'idiot destroying': 3,\n",
       " 'idiot destroying entire': 3,\n",
       " 'must watch': 3,\n",
       " 'plain sight': 3,\n",
       " 'always going': 3,\n",
       " 'back day': 3,\n",
       " 'white genocide': 3,\n",
       " 'balfour declaration': 3,\n",
       " 'von braun': 3}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39181c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_terms=[]\n",
    "for key in imp_terms:\n",
    "    important_terms.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7d3a6a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new world',\n",
       " 'world order',\n",
       " 'zionist occupied',\n",
       " 'united state',\n",
       " 'goy know',\n",
       " 'george soros',\n",
       " 'blood type',\n",
       " 'vatican ii',\n",
       " 'nostra aetate',\n",
       " 'occupied government',\n",
       " 'human right',\n",
       " 'jesus christ',\n",
       " 'deep state',\n",
       " 'zionist reptilian',\n",
       " 'far right',\n",
       " 'white people',\n",
       " 'jewish community',\n",
       " 'fascist white',\n",
       " 'new york',\n",
       " 'including zionist',\n",
       " 'church always',\n",
       " 'un special',\n",
       " 'late 20th',\n",
       " 'space time',\n",
       " 'space time information',\n",
       " 'time information',\n",
       " 'white power',\n",
       " 'african identity',\n",
       " 'zionist jewish',\n",
       " 'moon landing',\n",
       " 'middle east',\n",
       " 'critical race',\n",
       " 'church teaching',\n",
       " 'people color',\n",
       " 'civil right',\n",
       " 'world war',\n",
       " 'old school',\n",
       " 'zionist time',\n",
       " 'special rapporteur',\n",
       " 'un special rapporteur',\n",
       " 'federal reserve',\n",
       " 'white men',\n",
       " 'interfere behalf',\n",
       " 'say jew',\n",
       " 'throw jew',\n",
       " 'get rid',\n",
       " 'need get',\n",
       " 'zionist jew',\n",
       " 'klaus schwab',\n",
       " 'khazarian satanist',\n",
       " 'mel gibson',\n",
       " 'central bank',\n",
       " 'sound like',\n",
       " 'social justice',\n",
       " 'american jew',\n",
       " 'jewish lobby group',\n",
       " 'lobby group',\n",
       " 'published online',\n",
       " 'always taught',\n",
       " 'church always taught',\n",
       " 'communist party',\n",
       " 'ruling class',\n",
       " 'jew well',\n",
       " 'throw jew well',\n",
       " 'real jew',\n",
       " 'go back',\n",
       " 'khazarian mafia',\n",
       " 'white house',\n",
       " 'jewish cabal',\n",
       " 'national socialist',\n",
       " 'destroying nation',\n",
       " 'destroying entire',\n",
       " 'full disclosure',\n",
       " 'state america',\n",
       " 'united state america',\n",
       " 'military operation',\n",
       " 'year ago',\n",
       " 'air traffic',\n",
       " 'public service',\n",
       " 'white american',\n",
       " 'german people',\n",
       " '20th century',\n",
       " 'white race',\n",
       " 'jew accept',\n",
       " 'jew reject',\n",
       " 'organized jewry',\n",
       " 'roy cohn',\n",
       " 'elite killed',\n",
       " 'hollywood elite',\n",
       " 'hollywood elite killed',\n",
       " 'globalists cabal',\n",
       " 'world economic',\n",
       " 'accursed guilty',\n",
       " 'ethnic foids',\n",
       " 'manhattan new',\n",
       " 'manhattan new york',\n",
       " 'new york city',\n",
       " 'york city',\n",
       " 'cultural marxist',\n",
       " 'name zionist',\n",
       " 'blame slav',\n",
       " 'mayer amschel',\n",
       " 'political correctness',\n",
       " 'interest group',\n",
       " 'african identity black',\n",
       " 'identity black',\n",
       " 'frankfurt school',\n",
       " 'one listening',\n",
       " 'nazi germany',\n",
       " 'coup attempt',\n",
       " 'rothschild family',\n",
       " 'western civilization',\n",
       " 'chairman jewish',\n",
       " 'chairman jewish lobby',\n",
       " 'anti white',\n",
       " 'catholic church',\n",
       " 'meet new',\n",
       " 'million dollar',\n",
       " 'would say',\n",
       " 'jewish elite',\n",
       " 'nancy pelosi',\n",
       " 'de rothschild',\n",
       " 'jeffrey epstein',\n",
       " 'also need',\n",
       " 'grand marshal',\n",
       " 'american lunar',\n",
       " 'crowning achievement',\n",
       " 'took place',\n",
       " 'donald trump',\n",
       " 'financial system',\n",
       " 'intelligence gathering',\n",
       " 'joe biden',\n",
       " 'ancient israelite',\n",
       " 'cancer destroying',\n",
       " 'cancer destroying middle',\n",
       " 'destroying middle',\n",
       " 'destroying middle east',\n",
       " 'twin cancer',\n",
       " 'twin cancer destroying',\n",
       " 'national security',\n",
       " 'social medium',\n",
       " 'air traffic control',\n",
       " 'traffic control',\n",
       " 'american jewish',\n",
       " 'christ cursed',\n",
       " 'special military',\n",
       " 'special military operation',\n",
       " 'mike tyson',\n",
       " 'fema camp',\n",
       " 'cabal need',\n",
       " 'zog zionist occupied',\n",
       " 'pulled wef',\n",
       " 'zog zionist',\n",
       " 'fuck new',\n",
       " 'fuck new world',\n",
       " 'dont let',\n",
       " 'queen story',\n",
       " 'queen story time',\n",
       " 'story time',\n",
       " 'keep getting',\n",
       " 'zionist jewish cabal',\n",
       " 'deep state cabal',\n",
       " 'state cabal',\n",
       " 'jacob rothschild',\n",
       " 'usa get',\n",
       " 'elite killed unborn',\n",
       " 'killed unborn',\n",
       " 'killed unborn child',\n",
       " 'unborn child',\n",
       " 'color revolution',\n",
       " 'jewish people',\n",
       " 'agent embedded',\n",
       " 'end game',\n",
       " 'open society',\n",
       " 'orthodox christian',\n",
       " 'mental illness',\n",
       " 'therefore america',\n",
       " 'rejected christ',\n",
       " 'german christian',\n",
       " 'holy war',\n",
       " 'across video',\n",
       " 'across video must',\n",
       " 'anti white genocide',\n",
       " 'came across',\n",
       " 'came across video',\n",
       " 'video must',\n",
       " 'video must watch',\n",
       " 'destroy america',\n",
       " 'jewish banker',\n",
       " 'entry new',\n",
       " 'entry new world',\n",
       " 'idiot destroying',\n",
       " 'idiot destroying entire',\n",
       " 'must watch',\n",
       " 'plain sight',\n",
       " 'always going',\n",
       " 'back day',\n",
       " 'white genocide',\n",
       " 'balfour declaration',\n",
       " 'von braun']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "314f03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_text=\" \".join(uncleaned_lematised_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8004fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_terms=[]\n",
    "for term in important_terms:\n",
    "    match=re.search(r'\\b'+re.escape(term)+r'\\b',merged_text)\n",
    "    if match:\n",
    "        new_terms.append(match.group(0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "699a05e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79660c6",
   "metadata": {},
   "source": [
    "### Lets first remove the appearence terms to make it emerging terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78aa6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_glossary=[]\n",
    "for term in glossary:\n",
    "    if len(term.split(\" \"))==1:\n",
    "        new_glossary.append(term)\n",
    "    elif len(term.split(\" \"))==2:\n",
    "        new_glossary.append(term.split()[0])\n",
    "        new_glossary.append(term.split()[1])\n",
    "    else:\n",
    "        terms=list(zip(term.split()[:-1],term.split()[1:]))\n",
    "        pairs=[' '.join(i)  for i in terms]\n",
    "        pairs.append(' '.join([term.split()[0],term.split()[-1]]))\n",
    "        new_glossary+=pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6b0c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in new_glossary:\n",
    "    for t in new_terms:\n",
    "        if g in t:\n",
    "            new_terms.remove(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010095b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "c6d21dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "if 'cabal' in 'statecabalone':\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d261a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['united state',\n",
       " 'goy know',\n",
       " 'blood type',\n",
       " 'vatican ii',\n",
       " 'nostra aetate',\n",
       " 'human right',\n",
       " 'jesus christ',\n",
       " 'deep state',\n",
       " 'far right',\n",
       " 'white people',\n",
       " 'fascist white',\n",
       " 'new york',\n",
       " 'church always',\n",
       " 'un special',\n",
       " 'late 20th',\n",
       " 'space time',\n",
       " 'space time information',\n",
       " 'time information',\n",
       " 'white power',\n",
       " 'african identity',\n",
       " 'moon landing',\n",
       " 'middle east',\n",
       " 'critical race',\n",
       " 'church teaching',\n",
       " 'civil right',\n",
       " 'world war',\n",
       " 'old school',\n",
       " 'special rapporteur',\n",
       " 'un special rapporteur',\n",
       " 'federal reserve',\n",
       " 'white men',\n",
       " 'get rid',\n",
       " 'klaus schwab',\n",
       " 'khazarian satanist',\n",
       " 'mel gibson',\n",
       " 'central bank',\n",
       " 'sound like',\n",
       " 'social justice',\n",
       " 'always taught',\n",
       " 'church always taught',\n",
       " 'ruling class',\n",
       " 'go back',\n",
       " 'khazarian mafia',\n",
       " 'white house',\n",
       " 'national socialist',\n",
       " 'destroying nation',\n",
       " 'destroying entire',\n",
       " 'full disclosure',\n",
       " 'military operation',\n",
       " 'year ago',\n",
       " 'air traffic',\n",
       " 'public service',\n",
       " 'white american',\n",
       " 'german people',\n",
       " '20th century',\n",
       " 'white race',\n",
       " 'roy cohn',\n",
       " 'hollywood elite',\n",
       " 'world economic',\n",
       " 'ethnic foids',\n",
       " 'manhattan new',\n",
       " 'manhattan new york',\n",
       " 'new york city',\n",
       " 'york city',\n",
       " 'mayer amschel',\n",
       " 'political correctness',\n",
       " 'interest group',\n",
       " 'african identity black',\n",
       " 'identity black',\n",
       " 'frankfurt school',\n",
       " 'nazi germany',\n",
       " 'coup attempt',\n",
       " 'western civilization',\n",
       " 'anti white',\n",
       " 'catholic church',\n",
       " 'million dollar',\n",
       " 'would say',\n",
       " 'nancy pelosi',\n",
       " 'jeffrey epstein',\n",
       " 'also need',\n",
       " 'grand marshal',\n",
       " 'american lunar',\n",
       " 'crowning achievement',\n",
       " 'took place',\n",
       " 'donald trump',\n",
       " 'financial system',\n",
       " 'intelligence gathering',\n",
       " 'joe biden',\n",
       " 'cancer destroying',\n",
       " 'twin cancer',\n",
       " 'twin cancer destroying',\n",
       " 'national security',\n",
       " 'social medium',\n",
       " 'air traffic control',\n",
       " 'traffic control',\n",
       " 'special military',\n",
       " 'special military operation',\n",
       " 'mike tyson',\n",
       " 'fema camp',\n",
       " 'zog zionist',\n",
       " 'dont let',\n",
       " 'queen story',\n",
       " 'queen story time',\n",
       " 'story time',\n",
       " 'keep getting',\n",
       " 'deep state cabal',\n",
       " 'usa get',\n",
       " 'unborn child',\n",
       " 'color revolution',\n",
       " 'agent embedded',\n",
       " 'end game',\n",
       " 'open society',\n",
       " 'orthodox christian',\n",
       " 'mental illness',\n",
       " 'therefore america',\n",
       " 'rejected christ',\n",
       " 'german christian',\n",
       " 'holy war',\n",
       " 'anti white genocide',\n",
       " 'came across',\n",
       " 'destroy america',\n",
       " 'idiot destroying',\n",
       " 'idiot destroying entire',\n",
       " 'must watch',\n",
       " 'plain sight',\n",
       " 'always going',\n",
       " 'white genocide',\n",
       " 'balfour declaration',\n",
       " 'von braun']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416e3e6",
   "metadata": {},
   "source": [
    "### Removing obvious jewish relevent terms to make it coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ef6b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jewish_topics=['kike','jew','zionist','nazi']\n",
    "for j in jewish_topics:\n",
    "    for t in new_terms:\n",
    "        if j in t:\n",
    "            new_terms.remove(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b685d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0471e341",
   "metadata": {},
   "source": [
    "### Get the original form of the term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ea8c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams=[]\n",
    "for term in new_terms:\n",
    "    if len(term.split())==3:\n",
    "        trigrams.append(term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abcc3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing bigrams if they are already in trigrams\n",
    "for exp in trigrams:\n",
    "    terms=list(zip(exp.split()[:-1],exp.split()[1:]))\n",
    "    pairs=[' '.join(i)  for i in terms]\n",
    "    pairs.append(' '.join([exp.split()[0],exp.split()[-1]]))\n",
    "    if pairs[0] in new_terms:\n",
    "        new_terms.remove(pairs[0])\n",
    "    if pairs[1] in new_terms:\n",
    "        new_terms.remove(pairs[1])\n",
    "    if pairs[2] in new_terms:\n",
    "        new_terms.remove(pairs[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ede31c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bef3aec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['united state',\n",
       " 'goy know',\n",
       " 'blood type',\n",
       " 'vatican ii',\n",
       " 'nostra aetate',\n",
       " 'human right',\n",
       " 'jesus christ',\n",
       " 'far right',\n",
       " 'white people',\n",
       " 'fascist white',\n",
       " 'late 20th',\n",
       " 'space time information',\n",
       " 'white power',\n",
       " 'moon landing',\n",
       " 'middle east',\n",
       " 'critical race',\n",
       " 'church teaching',\n",
       " 'civil right',\n",
       " 'world war',\n",
       " 'old school',\n",
       " 'un special rapporteur',\n",
       " 'federal reserve',\n",
       " 'white men',\n",
       " 'get rid',\n",
       " 'klaus schwab',\n",
       " 'khazarian satanist',\n",
       " 'mel gibson',\n",
       " 'central bank',\n",
       " 'sound like',\n",
       " 'social justice',\n",
       " 'church always taught',\n",
       " 'ruling class',\n",
       " 'go back',\n",
       " 'khazarian mafia',\n",
       " 'white house',\n",
       " 'national socialist',\n",
       " 'destroying nation',\n",
       " 'full disclosure',\n",
       " 'year ago',\n",
       " 'public service',\n",
       " 'white american',\n",
       " 'german people',\n",
       " '20th century',\n",
       " 'white race',\n",
       " 'roy cohn',\n",
       " 'hollywood elite',\n",
       " 'world economic',\n",
       " 'ethnic foids',\n",
       " 'manhattan new york',\n",
       " 'new york city',\n",
       " 'mayer amschel',\n",
       " 'political correctness',\n",
       " 'interest group',\n",
       " 'african identity black',\n",
       " 'frankfurt school',\n",
       " 'coup attempt',\n",
       " 'western civilization',\n",
       " 'catholic church',\n",
       " 'million dollar',\n",
       " 'would say',\n",
       " 'nancy pelosi',\n",
       " 'jeffrey epstein',\n",
       " 'also need',\n",
       " 'grand marshal',\n",
       " 'american lunar',\n",
       " 'crowning achievement',\n",
       " 'took place',\n",
       " 'donald trump',\n",
       " 'financial system',\n",
       " 'intelligence gathering',\n",
       " 'joe biden',\n",
       " 'twin cancer destroying',\n",
       " 'national security',\n",
       " 'social medium',\n",
       " 'air traffic control',\n",
       " 'special military operation',\n",
       " 'mike tyson',\n",
       " 'fema camp',\n",
       " 'dont let',\n",
       " 'queen story time',\n",
       " 'keep getting',\n",
       " 'deep state cabal',\n",
       " 'usa get',\n",
       " 'unborn child',\n",
       " 'color revolution',\n",
       " 'agent embedded',\n",
       " 'end game',\n",
       " 'open society',\n",
       " 'orthodox christian',\n",
       " 'mental illness',\n",
       " 'therefore america',\n",
       " 'rejected christ',\n",
       " 'german christian',\n",
       " 'holy war',\n",
       " 'anti white genocide',\n",
       " 'came across',\n",
       " 'destroy america',\n",
       " 'idiot destroying entire',\n",
       " 'must watch',\n",
       " 'plain sight',\n",
       " 'always going',\n",
       " 'balfour declaration',\n",
       " 'von braun']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "76aeed6f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor t in glossary:\\n    s=[]\\n    if len(t.split())==2:\\n        s.append(t.split()[0])\\n        s.append(t.split()[1])\\n        for term in new_terms:\\n            if t in term or s[0] in term or s[1] in term:\\n                new_terms.remove(term)\\n    else:\\n        for term in new_terms:\\n            if t in term:\\n                new_terms.remove(term)\\n'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for t in glossary:\n",
    "    s=[]\n",
    "    if len(t.split())==2:\n",
    "        s.append(t.split()[0])\n",
    "        s.append(t.split()[1])\n",
    "        for term in new_terms:\n",
    "            if t in term or s[0] in term or s[1] in term:\n",
    "                new_terms.remove(term)\n",
    "    else:\n",
    "        for term in new_terms:\n",
    "            if t in term:\n",
    "                new_terms.remove(term)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "fa07a141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zionist', 'government']"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['zionist occupied government'.split()[0],'zionist occupied government'.split()[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89e5bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_terms.remove('zog zionist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e100753",
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary=['cabal','cultural marxism','deicide','holocough','jewish capitalist','the goyim know',\n",
    "           'jewish communist','jewish lobby','new world order','rothschild', 'soros','zionist',\n",
    "         'zionist occupied government','not the real jews','jew down','cosmopolitan elite'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac709c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressions=glossary+new_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ef0e690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holocough',\n",
       " 'not the real jews',\n",
       " 'cultural marxism',\n",
       " 'jew down',\n",
       " 'the goyim know',\n",
       " 'deicide',\n",
       " 'jewish capitalist',\n",
       " 'soros',\n",
       " 'cabal',\n",
       " 'zionist',\n",
       " 'zionist occupied government',\n",
       " 'cosmopolitan elite',\n",
       " 'jewish communist',\n",
       " 'jewish lobby',\n",
       " 'rothschild',\n",
       " 'new world order']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(glossary).difference(new_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "id": "7faa94a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fema is not a good thing! fema camp are concentration camps. fema camp are the end game of the new world order\n",
      "++++++++++++++++++++++++++++++\n",
      "i am the deep state. i hacked into the irs and photoshoped this image under direction from the george soros initiative. later today i will connect to the 5g tower to let dark brandon know our mission is going a planned. our set up and partnership with the doj and jack smith will soon be complete. once we indict trump then we will censor magas and start putting them into fema camp for detention.\n",
      "++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for text in uncleaned_lematised_text:\n",
    "    if \"fema camp\" in text:\n",
    "        print(text)\n",
    "        print('++++++++++++++++++++++++++++++')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "id": "273f47e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jesuit',\n",
       " 'joe',\n",
       " 'bid',\n",
       " '##en',\n",
       " ',',\n",
       " 'global',\n",
       " '##ist',\n",
       " 'puppet',\n",
       " '.',\n",
       " 'tool',\n",
       " 'of',\n",
       " 'the',\n",
       " 'trillion',\n",
       " '##aire',\n",
       " ',',\n",
       " 'jacob',\n",
       " 'rothschild',\n",
       " 'and',\n",
       " 'his',\n",
       " 'k',\n",
       " '##ha',\n",
       " '##zar',\n",
       " '##ian',\n",
       " 'mafia',\n",
       " 'minions',\n",
       " '.',\n",
       " 'the',\n",
       " 'global',\n",
       " '##ists',\n",
       " 'are',\n",
       " 'being',\n",
       " 'exposed',\n",
       " 'worldwide',\n",
       " 'and',\n",
       " 'the',\n",
       " 'mass',\n",
       " 'are',\n",
       " 'rejecting',\n",
       " 'their',\n",
       " \"'\",\n",
       " 'great',\n",
       " 'reset',\n",
       " '.',\n",
       " 'now',\n",
       " 'they',\n",
       " 'have',\n",
       " 'intensified',\n",
       " 'their',\n",
       " 'dangerous',\n",
       " 'and',\n",
       " 'desperate',\n",
       " 'tactic',\n",
       " 'to',\n",
       " 'fight',\n",
       " 'back',\n",
       " 'against',\n",
       " 'the',\n",
       " 'ser',\n",
       " '##f',\n",
       " 'and',\n",
       " 'slave',\n",
       " 'they',\n",
       " 'wish',\n",
       " 'to',\n",
       " 'control',\n",
       " '.',\n",
       " 'a',\n",
       " 'main',\n",
       " 'goal',\n",
       " 'is',\n",
       " 'to',\n",
       " 'de',\n",
       " '##pop',\n",
       " '##ulate',\n",
       " 'the',\n",
       " 'earth',\n",
       " '.',\n",
       " 'it',\n",
       " 'easier',\n",
       " 'to',\n",
       " 'control',\n",
       " 'le',\n",
       " 'of',\n",
       " 'us',\n",
       " '.',\n",
       " 'bid',\n",
       " '##en',\n",
       " '=',\n",
       " 'bi',\n",
       " '##lder',\n",
       " '##berg',\n",
       " \"'\",\n",
       " 's',\n",
       " 'idiot',\n",
       " 'destroying',\n",
       " 'entire',\n",
       " 'nation',\n",
       " '.']"
      ]
     },
     "execution_count": 1138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"jesuit joe biden, globalist puppet. tool of the trillionaire, jacob rothschild and his khazarian mafia minions. the globalists are being exposed worldwide and the mass are rejecting their 'great reset. now they have intensified their dangerous and desperate tactic to fight back against the serf and slave they wish to control. a main goal is to depopulate the earth. it easier to control le of us. biden = bilderberg's idiot destroying entire nation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "id": "0a0fef1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'>>414172699': 1,\n",
       "         'great': 3,\n",
       "         'reset': 2,\n",
       "         'next': 2,\n",
       "         'week>jfk': 1,\n",
       "         'princess': 2,\n",
       "         'diana': 1,\n",
       "         'back>trump': 1,\n",
       "         'president>trump': 1,\n",
       "         'biden': 10,\n",
       "         'crime': 3,\n",
       "         'did>the': 1,\n",
       "         'cabal': 1,\n",
       "         'exterminated>god': 1,\n",
       "         'bless': 1,\n",
       "         'youqtards': 1,\n",
       "         'live': 1,\n",
       "         'imaginary': 1,\n",
       "         'world.article': 1,\n",
       "         \"putin's\": 1,\n",
       "         'role': 1,\n",
       "         'reset/globalization': 1,\n",
       "         'putin': 1,\n",
       "         'xi': 1,\n",
       "         'multipolar': 1,\n",
       "         'eurasian': 1,\n",
       "         'plan': 3,\n",
       "         '(global': 1,\n",
       "         'jewish-communist': 1,\n",
       "         'slavery)': 1,\n",
       "         'eastern': 1,\n",
       "         'western': 7,\n",
       "         'jew': 3,\n",
       "         'lockstep': 1,\n",
       "         'kissinger': 1,\n",
       "         'dugin': 1,\n",
       "         'jewish': 2,\n",
       "         'collapse': 4,\n",
       "         'west': 5,\n",
       "         'full': 1,\n",
       "         'swing': 1,\n",
       "         'europe': 1,\n",
       "         'destroy': 1,\n",
       "         'civilization': 1,\n",
       "         'pre-planned': 1,\n",
       "         'ww3': 1,\n",
       "         'deception': 1,\n",
       "         'sino-soviet': 1,\n",
       "         'scissors': 1,\n",
       "         'strategybiden': 1,\n",
       "         'clown': 1,\n",
       "         'show': 3,\n",
       "         'useless': 1,\n",
       "         'goal': 2,\n",
       "         'globalist': 2,\n",
       "         'stooge': 1,\n",
       "         'economy': 1,\n",
       "         'entry': 1,\n",
       "         'new': 14,\n",
       "         'world': 10,\n",
       "         'order/great': 1,\n",
       "         'reset/liberal': 1,\n",
       "         'order,': 2,\n",
       "         'global': 2,\n",
       "         'village,': 1,\n",
       "         'international': 3,\n",
       "         'schitte': 1,\n",
       "         'different': 1,\n",
       "         'name.part': 1,\n",
       "         '#digitalcontrolgrid': 1,\n",
       "         'cash': 2,\n",
       "         '(mon)ey(e),': 1,\n",
       "         'eye': 1,\n",
       "         'money': 5,\n",
       "         '#cbdc': 1,\n",
       "         '#cbdcs': 1,\n",
       "         'digital': 1,\n",
       "         'end': 1,\n",
       "         'human': 1,\n",
       "         'freedom.': 1,\n",
       "         'control': 3,\n",
       "         'system': 5,\n",
       "         'planned': 1,\n",
       "         'money.': 1,\n",
       "         'case': 2,\n",
       "         'it,': 1,\n",
       "         '#weareatwar': 1,\n",
       "         '#darkoccult': 1,\n",
       "         'order': 4,\n",
       "         'reset.>>407694962': 1,\n",
       "         'bed': 1,\n",
       "         'administrators>try': 1,\n",
       "         '\"great': 1,\n",
       "         'reset\"': 1,\n",
       "         '\"new': 1,\n",
       "         'order\"lollmaojesuit': 1,\n",
       "         'joe': 6,\n",
       "         'biden,': 3,\n",
       "         'puppet.': 1,\n",
       "         'tool': 1,\n",
       "         'trillionaire,': 1,\n",
       "         'jacob': 1,\n",
       "         'rothschild': 1,\n",
       "         'khazarian': 1,\n",
       "         'mafia': 1,\n",
       "         'globalists': 1,\n",
       "         'worldwide': 1,\n",
       "         'mass': 1,\n",
       "         \"'great\": 1,\n",
       "         'reset.\"': 1,\n",
       "         'dangerous': 1,\n",
       "         'desperate': 1,\n",
       "         'tactic': 1,\n",
       "         'serf': 1,\n",
       "         'wish': 1,\n",
       "         'main': 3,\n",
       "         'earth.': 1,\n",
       "         'us.': 2,\n",
       "         '=': 1,\n",
       "         \"bilderberg's\": 1,\n",
       "         'idiot': 1,\n",
       "         'entire': 2,\n",
       "         'nation.mccarthy': 1,\n",
       "         'â€œpresidentâ€\\x9d': 1,\n",
       "         'un': 3,\n",
       "         'prepares': 1,\n",
       "         'tectonic': 1,\n",
       "         'shift': 1,\n",
       "         'place': 6,\n",
       "         'geopolitical': 1,\n",
       "         'power': 9,\n",
       "         'structure': 1,\n",
       "         'past': 1,\n",
       "         'week.': 1,\n",
       "         'result': 1,\n",
       "         'avatar': 4,\n",
       "         'â€œjoe': 1,\n",
       "         'biden,â€\\x9d': 2,\n",
       "         'president': 3,\n",
       "         'house': 2,\n",
       "         'speaker': 2,\n",
       "         'mccarthy,': 1,\n",
       "         'pentagon': 1,\n",
       "         'mi6': 5,\n",
       "         'source': 8,\n",
       "         'say.': 1,\n",
       "         'also,': 1,\n",
       "         'preparation': 1,\n",
       "         'headquarters': 2,\n",
       "         'york': 1,\n",
       "         'earnest,': 1,\n",
       "         'cia': 2,\n",
       "         'lao': 2,\n",
       "         'say.these': 1,\n",
       "         'change': 1,\n",
       "         'culprit': 1,\n",
       "         'present': 1,\n",
       "         'dysfunctional': 1,\n",
       "         'state': 2,\n",
       "         'planet': 2,\n",
       "         'gather': 1,\n",
       "         'davos,': 1,\n",
       "         'switzerland': 1,\n",
       "         'economic': 3,\n",
       "         'forum.': 1,\n",
       "         'report': 4,\n",
       "         'live,': 1,\n",
       "         'say': 2,\n",
       "         'head': 5,\n",
       "         'organization,': 1,\n",
       "         'klaus': 2,\n",
       "         'schwab': 2,\n",
       "         'rothschild,': 1,\n",
       "         'opening': 1,\n",
       "         'wef': 3,\n",
       "         'conference': 1,\n",
       "         'davos': 2,\n",
       "         'today': 1,\n",
       "         'â€œdue': 1,\n",
       "         'health': 1,\n",
       "         'issueâ€\\x9d.': 1,\n",
       "         'disinformation': 1,\n",
       "         'trap': 1,\n",
       "         'credibility': 1,\n",
       "         'newsletter': 1,\n",
       "         'appear': 1,\n",
       "         'absence.': 1,\n",
       "         'unavailable': 1,\n",
       "         'comment.': 1,\n",
       "         'regardless,': 1,\n",
       "         'criminal': 1,\n",
       "         'gathering': 2,\n",
       "         'battle': 1,\n",
       "         'earth,': 1,\n",
       "         'multiple': 1,\n",
       "         'know': 2,\n",
       "         'hitler/rockefeller': 1,\n",
       "         'branch': 1,\n",
       "         'ruling': 5,\n",
       "         'class': 5,\n",
       "         'descendant': 1,\n",
       "         'adolph': 1,\n",
       "         'hitler': 1,\n",
       "         'john': 2,\n",
       "         'rockefeller': 3,\n",
       "         'angela': 1,\n",
       "         'merkel,': 1,\n",
       "         'hillary': 1,\n",
       "         'clinton,': 1,\n",
       "         'barack': 2,\n",
       "         'obama,': 1,\n",
       "         'david': 2,\n",
       "         'jr.,': 1,\n",
       "         'etc.': 3,\n",
       "         'titles,': 1,\n",
       "         'say.to': 1,\n",
       "         'confirm': 1,\n",
       "         'true,': 1,\n",
       "         'need': 1,\n",
       "         'public': 4,\n",
       "         'removal': 2,\n",
       "         'avatar,': 1,\n",
       "         'â€œpresident': 1,\n",
       "         'rubber': 1,\n",
       "         'mask-wearing': 1,\n",
       "         'phony': 2,\n",
       "         'pope': 4,\n",
       "         'sign': 2,\n",
       "         'us,': 1,\n",
       "         'struggle': 1,\n",
       "         'compromise': 1,\n",
       "         'wherein': 1,\n",
       "         'donald': 5,\n",
       "         'trump': 6,\n",
       "         'power.': 1,\n",
       "         'supreme': 2,\n",
       "         'court': 2,\n",
       "         'brunson': 1,\n",
       "         'election': 2,\n",
       "         'president.': 1,\n",
       "         'reason': 1,\n",
       "         'january': 2,\n",
       "         'vaccine-pushing': 1,\n",
       "         'fraud.': 1,\n",
       "         'real': 8,\n",
       "         'trump,': 1,\n",
       "         'son': 2,\n",
       "         'barron': 1,\n",
       "         'vaccines,': 1,\n",
       "         'rockefellers,': 1,\n",
       "         'rothschilds.so,': 1,\n",
       "         'serious': 1,\n",
       "         'horse-trading': 1,\n",
       "         'round': 1,\n",
       "         'vote': 1,\n",
       "         'kevin': 1,\n",
       "         'mccarthy': 3,\n",
       "         'house.': 1,\n",
       "         'things,': 2,\n",
       "         'hearing': 1,\n",
       "         'fbi': 1,\n",
       "         'malignant': 1,\n",
       "         'force': 3,\n",
       "         'american': 3,\n",
       "         'patriots.': 1,\n",
       "         'intelligence': 3,\n",
       "         'kamala': 1,\n",
       "         'harris,': 1,\n",
       "         'second': 1,\n",
       "         'line': 1,\n",
       "         'presidency.': 1,\n",
       "         'interim': 1,\n",
       "         'figure': 2,\n",
       "         'new,': 1,\n",
       "         'genuine,': 1,\n",
       "         'elections.': 1,\n",
       "         'headline': 1,\n",
       "         'corporate': 1,\n",
       "         'propaganda': 1,\n",
       "         'media:former': 1,\n",
       "         'clinton': 1,\n",
       "         'adviser': 1,\n",
       "         'gergen': 1,\n",
       "         'risk': 1,\n",
       "         'doc': 1,\n",
       "         'case:': 1,\n",
       "         'â€˜very,': 1,\n",
       "         'big': 2,\n",
       "         'dealâ€™': 1,\n",
       "         'â€œdocuments': 1,\n",
       "         'garageâ€\\x9d': 1,\n",
       "         'story': 1,\n",
       "         'child': 1,\n",
       "         'rape': 1,\n",
       "         'murder': 2,\n",
       "         'government': 4,\n",
       "         'gangster': 1,\n",
       "         'ukraine': 4,\n",
       "         'excuse': 1,\n",
       "         'farce.': 1,\n",
       "         'farce': 1,\n",
       "         'notice': 1,\n",
       "         'fake': 3,\n",
       "         'doesnâ€™t': 1,\n",
       "         'blink': 1,\n",
       "         'video.': 1,\n",
       "         'likely': 2,\n",
       "         'cgi': 1,\n",
       "         'dumb': 1,\n",
       "         'cannot': 2,\n",
       "         'last': 3,\n",
       "         'much': 1,\n",
       "         'longer.we': 1,\n",
       "         'strong': 1,\n",
       "         'campaign': 2,\n",
       "         'â€œpope': 1,\n",
       "         'francis.â€\\x9d': 1,\n",
       "         'news': 3,\n",
       "         'plot': 1,\n",
       "         'earnestâ€\\x9d': 1,\n",
       "         'benedict': 2,\n",
       "         '(maledict)': 1,\n",
       "         'xvi': 1,\n",
       "         'december': 1,\n",
       "         'sudden': 1,\n",
       "         'death': 3,\n",
       "         'vatican': 2,\n",
       "         'bank,': 1,\n",
       "         'cardinal': 1,\n",
       "         'george': 1,\n",
       "         'pell,': 1,\n",
       "         'battle.': 1,\n",
       "         'pell': 1,\n",
       "         'ally': 1,\n",
       "         'francis': 4,\n",
       "         'â€œdisasterâ€\\x9d': 1,\n",
       "         'â€œcatastrophe.â€\\x9d': 1,\n",
       "         'case,': 4,\n",
       "         'p3': 1,\n",
       "         'appearance': 1,\n",
       "         'day': 2,\n",
       "         'row': 1,\n",
       "         'â€œa': 1,\n",
       "         'mysterious': 2,\n",
       "         'sure': 2,\n",
       "         'sort': 2,\n",
       "         'purge': 1,\n",
       "         'level': 1,\n",
       "         'recent': 1,\n",
       "         'week': 2,\n",
       "         'top': 1,\n",
       "         'chinese': 1,\n",
       "         'broker': 1,\n",
       "         'jiang': 1,\n",
       "         'zemin,': 1,\n",
       "         'queen': 1,\n",
       "         'ii,': 1,\n",
       "         'etc.we': 1,\n",
       "         'fact': 2,\n",
       "         'm1': 4,\n",
       "         'committee': 2,\n",
       "         'controller': 1,\n",
       "         'financial': 5,\n",
       "         'contact': 1,\n",
       "         'individual,': 1,\n",
       "         'european': 2,\n",
       "         'royal': 2,\n",
       "         'person': 1,\n",
       "         'â€œm1': 1,\n",
       "         'monetary': 2,\n",
       "         'underwriting': 1,\n",
       "         'worldâ€™s': 1,\n",
       "         'banksâ€¦.': 1,\n",
       "         'legal': 1,\n",
       "         'signatory': 1,\n",
       "         'debt.': 1,\n",
       "         'canâ€™t': 1,\n",
       "         'country': 3,\n",
       "         'debt': 4,\n",
       "         'air': 1,\n",
       "         'someone.â€\\x9dthe': 1,\n",
       "         'obstacle': 1,\n",
       "         'jubilee': 3,\n",
       "         'establishment': 1,\n",
       "         'meritocratic': 1,\n",
       "         'future': 1,\n",
       "         'planning': 1,\n",
       "         'agency': 1,\n",
       "         'â€œstalemate': 1,\n",
       "         'fifth': 1,\n",
       "         'column': 1,\n",
       "         'mi6.â€\\x9d': 1,\n",
       "         'group': 1,\n",
       "         'illuminati': 3,\n",
       "         'upset,': 1,\n",
       "         'use': 1,\n",
       "         'charles': 1,\n",
       "         'face': 1,\n",
       "         'british': 2,\n",
       "         'monarchy': 1,\n",
       "         'alleged': 1,\n",
       "         'involvement': 1,\n",
       "         'diana.charles': 1,\n",
       "         'story:â€œiranian': 1,\n",
       "         'military': 3,\n",
       "         'probable': 1,\n",
       "         'cause': 1,\n",
       "         'pakistan': 1,\n",
       "         'isi)': 1,\n",
       "         'law': 1,\n",
       "         'murdered)': 1,\n",
       "         '[dodi': 1,\n",
       "         'fayed]': 1,\n",
       "         'owner': 1,\n",
       "         'harrodâ€™s': 1,\n",
       "         'shop': 1,\n",
       "         'londonâ€¦diana': 1,\n",
       "         'secondary': 1,\n",
       "         'consequence': 1,\n",
       "         'assassinated': 1,\n",
       "         'primary': 1,\n",
       "         'laundering': 1,\n",
       "         'arm': 1,\n",
       "         'majesty': 1,\n",
       "         'queen,': 1,\n",
       "         'majestyâ€™s': 1,\n",
       "         'consort': 1,\n",
       "         'prince': 2,\n",
       "         'philip': 1,\n",
       "         'hand,': 1,\n",
       "         'act,': 1,\n",
       "         'part': 2,\n",
       "         'this.â€\\x9dthe': 1,\n",
       "         'â€œmi6': 1,\n",
       "         'did,': 1,\n",
       "         'fact,': 1,\n",
       "         'provide': 1,\n",
       "         'military-grade': 1,\n",
       "         'optical': 1,\n",
       "         'device': 1,\n",
       "         'sufficient': 1,\n",
       "         'disablement': 1,\n",
       "         'road': 1,\n",
       "         'traffic': 1,\n",
       "         'accidentâ€\\x9d': 1,\n",
       "         'sir': 1,\n",
       "         'scarlett': 1,\n",
       "         'one-mile': 1,\n",
       "         'radius': 1,\n",
       "         'scene.â€\\x9d': 1,\n",
       "         'former': 1,\n",
       "         'mi6,': 1,\n",
       "         'dr.': 1,\n",
       "         'michael': 1,\n",
       "         'dianaâ€™s': 1,\n",
       "         'honor': 1,\n",
       "         'killing': 1,\n",
       "         'pregnant': 1,\n",
       "         'fayedâ€™s': 1,\n",
       "         'twin': 1,\n",
       "         'knowledge': 1,\n",
       "         'family': 2,\n",
       "         'member,': 1,\n",
       "         'dispute': 1,\n",
       "         'start': 1,\n",
       "         'age,': 1,\n",
       "         'workaround': 1,\n",
       "         'needed.': 1,\n",
       "         'apparently,': 1,\n",
       "         'william': 1,\n",
       "         'throne': 1,\n",
       "         'father': 1,\n",
       "         'so,': 1,\n",
       "         'england': 1,\n",
       "         'king': 1,\n",
       "         'harold': 1,\n",
       "         'first': 1,\n",
       "         'time': 2,\n",
       "         'throne.': 1,\n",
       "         'something': 1,\n",
       "         'privy': 1,\n",
       "         'council': 2,\n",
       "         'rest': 1,\n",
       "         'decision.there': 1,\n",
       "         'possibility': 1,\n",
       "         'general': 3,\n",
       "         'revolt': 1,\n",
       "         'bloodline': 1,\n",
       "         'west.': 1,\n",
       "         'ongoing': 1,\n",
       "         'fallout': 1,\n",
       "         'vaccine': 5,\n",
       "         'pandemic': 2,\n",
       "         'scam': 1,\n",
       "         'make': 1,\n",
       "         'bloody': 1,\n",
       "         'revolution': 1,\n",
       "         'likely.the': 1,\n",
       "         'gnostic': 1,\n",
       "         'warpath.': 1,\n",
       "         'mi': 1,\n",
       "         'â€œdavid': 1,\n",
       "         'tell': 1,\n",
       "         'so-called': 1,\n",
       "         'meâ€¦my': 1,\n",
       "         'instagram': 1,\n",
       "         'account': 2,\n",
       "         'various': 2,\n",
       "         'reference': 1,\n",
       "         'famous': 1,\n",
       "         'people': 2,\n",
       "         'strict': 1,\n",
       "         'press': 2,\n",
       "         'ban': 1,\n",
       "         'camera': 1,\n",
       "         'attempt': 2,\n",
       "         'back': 2,\n",
       "         'channel': 1,\n",
       "         'sa': 1,\n",
       "         'bodyguards.â€\\x9dhere': 1,\n",
       "         'message': 2,\n",
       "         'illuminati:cardinals': 1,\n",
       "         'degree': 1,\n",
       "         'freemason': 1,\n",
       "         'jesuit': 1,\n",
       "         'pope.': 1,\n",
       "         'mason': 1,\n",
       "         'command': 1,\n",
       "         'levels.': 1,\n",
       "         'step': 1,\n",
       "         '&gt;': 2,\n",
       "         'fortune': 1,\n",
       "         'blackrockin': 1,\n",
       "         'related,': 1,\n",
       "         'major': 1,\n",
       "         'fire': 1,\n",
       "         'masonic': 1,\n",
       "         'center': 1,\n",
       "         'south': 1,\n",
       "         'sydney.': 1,\n",
       "         'incite': 1,\n",
       "         'riot': 1,\n",
       "         'social': 2,\n",
       "         'unrest': 2,\n",
       "         'hemisphere.': 1,\n",
       "         'statement': 1,\n",
       "         'freedom': 1,\n",
       "         'fighter': 1,\n",
       "         'henry': 1,\n",
       "         'makow': 1,\n",
       "         'clear:pope': 1,\n",
       "         'imposter': 1,\n",
       "         'crypto-jew': 1,\n",
       "         '[km]': 2,\n",
       "         'â€œgreat': 1,\n",
       "         'resetâ€\\x9d': 1,\n",
       "         'covid-19': 1,\n",
       "         'scam.': 1,\n",
       "         'brother': 2,\n",
       "         'justin': 1,\n",
       "         'trudeau,': 1,\n",
       "         'emmanuel': 1,\n",
       "         'macron,': 1,\n",
       "         'jacinda': 1,\n",
       "         'ardern': 1,\n",
       "         'sister),': 1,\n",
       "         'obama': 2,\n",
       "         'michele': 1,\n",
       "         'jacinda),': 1,\n",
       "         'volodymyr': 1,\n",
       "         'zelenskyy,': 1,\n",
       "         'tedros': 1,\n",
       "         'ghebreyesus': 1,\n",
       "         'homosexual': 1,\n",
       "         'leader': 1,\n",
       "         'christianity': 1,\n",
       "         'cultures.the': 1,\n",
       "         'possible.': 1,\n",
       "         'hyperinflation,': 1,\n",
       "         'interest': 1,\n",
       "         'rates,': 1,\n",
       "         'market': 1,\n",
       "         'time.as': 1,\n",
       "         'chart': 2,\n",
       "         'housing': 1,\n",
       "         'bubble': 1,\n",
       "         'complete': 2,\n",
       "         'system.': 2,\n",
       "         'wage': 2,\n",
       "         'very,': 1,\n",
       "         'chart,': 1,\n",
       "         'fall': 1,\n",
       "         'underestimated,': 1,\n",
       "         'official': 2,\n",
       "         'inflation': 1,\n",
       "         'used,': 1,\n",
       "         'half': 1,\n",
       "         'inflation.': 1,\n",
       "         'tremendous': 1,\n",
       "         'rise': 1,\n",
       "         'breakdown': 1,\n",
       "         'united': 4,\n",
       "         'states.': 1,\n",
       "         'situation': 5,\n",
       "         'point': 1,\n",
       "         'grocery': 1,\n",
       "         'supermarket': 1,\n",
       "         'lock': 1,\n",
       "         'key.': 1,\n",
       "         'type': 1,\n",
       "         'unique': 1,\n",
       "         'poland,': 1,\n",
       "         'elderly': 1,\n",
       "         'food': 1,\n",
       "         'store': 1,\n",
       "         'murder,': 1,\n",
       "         'polish': 2,\n",
       "         'say.they': 1,\n",
       "         'note': 2,\n",
       "         'unit': 1,\n",
       "         'week,': 2,\n",
       "         'russian': 1,\n",
       "         'ukraine.in': 1,\n",
       "         'hungary,': 1,\n",
       "         'citizen': 1,\n",
       "         'national': 4,\n",
       "         'consultation': 1,\n",
       "         'eu': 1,\n",
       "         'sanction': 1,\n",
       "         'russia,': 1,\n",
       "         'alexandra': 1,\n",
       "         'sentkiraji,': 1,\n",
       "         'spokeswoman': 1,\n",
       "         'hungarian': 1,\n",
       "         'government.(due': 1,\n",
       "         'space': 7,\n",
       "         'limitations,': 1,\n",
       "         'detail': 1,\n",
       "         'page:': 1,\n",
       "         'true': 1,\n",
       "         'virtual': 1,\n",
       "         'private': 1,\n",
       "         'network': 1,\n",
       "         'access': 1,\n",
       "         'itâ€™s': 2,\n",
       "         'now,': 1,\n",
       "         'km': 2,\n",
       "         'fronts.': 1,\n",
       "         'place,': 1,\n",
       "         'mexican': 1,\n",
       "         'standoff': 1,\n",
       "         'mutual': 1,\n",
       "         'blackmail.': 1,\n",
       "         'mountain': 1,\n",
       "         'zug,': 1,\n",
       "         'switzerland,': 1,\n",
       "         'camp': 1,\n",
       "         'doubt': 1,\n",
       "         'file': 1,\n",
       "         'everyone': 2,\n",
       "         'position': 1,\n",
       "         'anywhere.': 1,\n",
       "         'powerful': 1,\n",
       "         'cults,': 1,\n",
       "         'incultated': 1,\n",
       "         'practice': 1,\n",
       "         'total': 2,\n",
       "         'control.': 1,\n",
       "         'cult': 1,\n",
       "         'scenes,': 1,\n",
       "         'thousand': 1,\n",
       "         'years.â€\\x9d': 1,\n",
       "         'kmâ€™s': 1,\n",
       "         'minds.': 1,\n",
       "         'damage': 1,\n",
       "         'extensive': 2,\n",
       "         'body': 1,\n",
       "         'cdc': 2,\n",
       "         'congress': 1,\n",
       "         'families,': 2,\n",
       "         'employee': 3,\n",
       "         'mandate': 1,\n",
       "         'demand': 1,\n",
       "         'employers,': 1,\n",
       "         'people.': 1,\n",
       "         'officer': 1,\n",
       "         'pharmaceutical': 1,\n",
       "         'company': 1,\n",
       "         'corruption': 1,\n",
       "         'whole': 1,\n",
       "         'neck': 1,\n",
       "         'it.': 1,\n",
       "         'way': 1,\n",
       "         'impasse': 1,\n",
       "         'proclamation': 1,\n",
       "         'truth': 1,\n",
       "         'reconciliation': 1,\n",
       "         'process,': 1,\n",
       "         'amnesty.': 1,\n",
       "         'amnesty': 1,\n",
       "         'crimes.it': 1,\n",
       "         'late': 1,\n",
       "         'current': 1,\n",
       "         'reforms.': 1,\n",
       "         'representative': 3,\n",
       "         'internal': 1,\n",
       "         'revenue': 1,\n",
       "         'service': 1,\n",
       "         '(irs),': 1,\n",
       "         'income': 1,\n",
       "         'tax': 3,\n",
       "         'consumption': 1,\n",
       "         'tax.': 1,\n",
       "         'state-issued': 1,\n",
       "         '(as': 1,\n",
       "         'km),': 1,\n",
       "         'excise': 1,\n",
       "         'required.in': 1,\n",
       "         'talk': 1,\n",
       "         'reform': 1,\n",
       "         'deckchairs': 1,\n",
       "         'titanic,': 1,\n",
       "         'society': 2,\n",
       "         'burner': 1,\n",
       "         'years.': 1,\n",
       "         'begging': 1,\n",
       "         'cup': 1,\n",
       "         'heirloom': 1,\n",
       "         'exchange': 2,\n",
       "         'quick': 1,\n",
       "         'fix.': 1,\n",
       "         'unfunded': 1,\n",
       "         '$300': 1,\n",
       "         'answer': 1,\n",
       "         'reset.the': 1,\n",
       "         'urgent': 1,\n",
       "         'm1,': 1,\n",
       "         'russians,': 1,\n",
       "         'chinese,': 1,\n",
       "         'brics,': 1,\n",
       "         'cooperation.sources': 1,\n",
       "         'white': 1,\n",
       "         'dragon': 1,\n",
       "         'non-western': 1,\n",
       "         'construction': 1,\n",
       "         'architecture.': 1,\n",
       "         'system.russian': 1,\n",
       "         'security': 2,\n",
       "         'secretary': 1,\n",
       "         'nikolai': 1,\n",
       "         'patrushev': 1,\n",
       "         'â€œcover': 1,\n",
       "         'conglomerate': 1,\n",
       "         'giant': 1,\n",
       "         'corporation': 2,\n",
       "         'run': 1,\n",
       "         'world.â€\\x9d': 1,\n",
       "         'â€œtransnational': 1,\n",
       "         'mere': 1,\n",
       "         'figurehead': 1,\n",
       "         '[donald]': 1,\n",
       "         'trump.': 1,\n",
       "         'republican': 1,\n",
       "         'democrat': 1,\n",
       "         'actor': 1,\n",
       "         'staging': 1,\n",
       "         'nothing': 1,\n",
       "         'democracy': 1,\n",
       "         'has.â€\\x9d': 1,\n",
       "         'permanent': 1,\n",
       "         'nations,': 1,\n",
       "         'nebenzia,': 1,\n",
       "         'peace': 1,\n",
       "         'negotiations,': 1,\n",
       "         'â€œthen': 1,\n",
       "         'task': 1,\n",
       "         'means.â€\\x9d': 1,\n",
       "         'possible': 1,\n",
       "         'hope': 1,\n",
       "         'relevant': 1,\n",
       "         'secret': 1,\n",
       "         'itself.': 1,\n",
       "         'release': 2,\n",
       "         'suggests:seven': 1,\n",
       "         'nation': 1,\n",
       "         'securityarlington,': 1,\n",
       "         'va.': 1,\n",
       "         '(afns)': 1,\n",
       "         'â€“the': 1,\n",
       "         'department': 1,\n",
       "         'defense': 1,\n",
       "         'annual': 1,\n",
       "         'cspo': 1,\n",
       "         'operations)': 1,\n",
       "         'initiativeâ€¦': 1,\n",
       "         'australia,': 1,\n",
       "         'canada,': 1,\n",
       "         'france,': 1,\n",
       "         'kingdom': 1,\n",
       "         'states,': 1,\n",
       "         'focus': 1,\n",
       "         'cooperation': 1,\n",
       "         'information': 1,\n",
       "         'issues.': 1,\n",
       "         'mind,': 1,\n",
       "         'space-themed': 1,\n",
       "         'images.': 1,\n",
       "         'geographic': 1,\n",
       "         'survey': 1,\n",
       "         'earthquake': 1,\n",
       "         'epicenter': 1,\n",
       "         'negative': 1,\n",
       "         'depth': 1,\n",
       "         'kilometers,': 1,\n",
       "         'kind': 1,\n",
       "         'explosion': 1,\n",
       "         'silicon': 1,\n",
       "         'valley': 1,\n",
       "         '(please': 1,\n",
       "         'correct': 1,\n",
       "         'wrong': 1,\n",
       "         ').': 1})"
      ]
     },
     "execution_count": 1058,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(great_reset.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4782e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "d41bd6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the goy know'"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lematize(\"the goyim know\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb28474",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef4cc5ab",
   "metadata": {},
   "source": [
    "## Extracting semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7040c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_context_words_bigram(sentence, target_bigram, num_words_before, num_words_after):\n",
    "    words = sentence.split()\n",
    "    context_words = []\n",
    "    if len(target_bigram.split())==4:\n",
    "        for i in range(len(words)-3):\n",
    "            fourgram=\" \".join([words[i],words[i+1],words[i+2],words[i+3]])\n",
    "            if fourgram==target_bigram:\n",
    "                start_index = max(0, i - num_words_before)\n",
    "                end_index = min(len(words), i + num_words_after + 4)\n",
    "                context_words.append(words[start_index:end_index])            \n",
    "    elif len(target_bigram.split())==3:\n",
    "        for i in range(len(words) - 2):  # Loop through pairs of consecutive words\n",
    "            trigram=\" \".join([words[i],words[i+1],words[i+2]])\n",
    "            if trigram == target_bigram: \n",
    "                start_index = max(0, i - num_words_before)\n",
    "                end_index = min(len(words), i + num_words_after + 3)\n",
    "                context_words.append(words[start_index:end_index])\n",
    "    else:\n",
    "        for i in range(len(words) - 1):  # Loop through pairs of consecutive words\n",
    "            bigram = \" \".join([words[i], words[i + 1]])\n",
    "            if bigram == target_bigram or words[i]==target_bigram:\n",
    "                start_index = max(0, i - num_words_before)\n",
    "                end_index = min(len(words), i + num_words_after + 2)\n",
    "                context_words.append(words[start_index:end_index])\n",
    "\n",
    "    return [\" \".join(i) for i in context_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d777ed9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.4085,  0.1897, -0.1800,  ..., -0.1144,  0.3407,  0.2681],\n",
       "         [-0.5121,  0.7198,  1.0164,  ..., -0.2408,  0.2927,  0.4201],\n",
       "         [ 0.0975,  0.1419,  0.9499,  ...,  0.0544,  0.1118,  0.5880],\n",
       "         ...,\n",
       "         [-0.1907,  0.2208,  0.6329,  ...,  0.2263, -0.1473, -0.2052],\n",
       "         [-0.1924, -0.1282, -0.0755,  ...,  0.9328,  0.2452, -0.8285],\n",
       "         [ 0.9104,  0.0798, -0.2145,  ...,  0.4522, -0.6772, -0.1402]],\n",
       "\n",
       "        [[-0.0407,  0.5450, -0.0261,  ..., -0.0495,  0.3516,  0.2268],\n",
       "         [ 0.4781,  0.0024, -0.1707,  ..., -0.4226,  0.6331, -0.0256],\n",
       "         [ 0.0359, -0.0916,  0.1373,  ..., -0.3269,  0.5405, -0.0678],\n",
       "         ...,\n",
       "         [ 0.8295,  0.0728, -0.2119,  ...,  0.1286, -0.5100, -0.2414],\n",
       "         [ 0.0700,  0.0281,  0.3272,  ...,  0.2974,  0.1447, -0.2613],\n",
       "         [-0.1064, -0.0894,  0.3124,  ...,  0.4626,  0.1871, -0.3429]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8443, -0.4341, -0.8013,  ..., -0.4365, -0.6932,  0.8783],\n",
       "        [-0.9211, -0.3871, -0.5079,  ..., -0.3269, -0.6597,  0.9314]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=tokenizer([\"hey buddy whtaspapp\",\"I am good man\"],return_tensors='pt',padding=True)\n",
    "m=model(**t)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "id": "0d88b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(Posts:list[str],Expression:list[str],rAnge:int):\n",
    "    terms_not_intext=[]\n",
    "    embed_dict={}\n",
    "    sent_dict={i:[] for i in Expression}\n",
    "    for term in Expression:\n",
    "        for post in Posts:\n",
    "            if term in post:\n",
    "                sents=extract_context_words_bigram(sentence=post,target_bigram=term,num_words_before=rAnge,num_words_after=rAnge)\n",
    "                if bool(sents):\n",
    "                    for sent in sents:\n",
    "                        sent_dict[term].append(sent)\n",
    "    for key in sent_dict:\n",
    "        if bool(sent_dict[key]):\n",
    "            sent_tokenize=tokenizer(sent_dict[key],return_tensors='pt',padding=True,max_length=512,truncation=True)\n",
    "            with torch.no_grad():\n",
    "                model_output=model(**sent_tokenize)['pooler_output']\n",
    "                embed_dict[key]=model_output\n",
    "        else:\n",
    "            terms_not_intext.append(key)\n",
    "        \n",
    "    return embed_dict,terms_not_intext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb86fa32",
   "metadata": {},
   "source": [
    "### This is to extracting embeddings as words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbec0991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3539 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "new_text_lematize=[]\n",
    "for text in uncleaned_lematised_text:\n",
    "    t=\"[CLS] \"+text+\" [SEP]\"\n",
    "    text_tokenize=tokenizer.tokenize(t)\n",
    "    if len(text_tokenize)>512:\n",
    "        chunks=len(text_tokenize)//512\n",
    "        chunk_size=len(text.split())//(chunks+1)\n",
    "        for i in range(chunks+1):\n",
    "            extracted_text=\" \".join(text.split(\" \")[i*chunk_size:(i+1)*chunk_size])\n",
    "            new_text_lematize.append(extracted_text)\n",
    "    else:\n",
    "        new_text_lematize.append(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37f45b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_text_lematize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d6e4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_unclean=[]\n",
    "for text in uncleaned_texts:\n",
    "    t=\"[CLS] \"+text+\" [SEP]\"\n",
    "    text_tokenize=tokenizer.tokenize(t)\n",
    "    if len(text_tokenize)>512:\n",
    "        chunks=len(text_tokenize)//512\n",
    "        chunk_size=len(text.split())//(chunks+1)\n",
    "        for i in range(chunks+1):\n",
    "            extracted_text=\" \".join(text.split(\" \")[i*chunk_size:(i+1)*chunk_size])\n",
    "            new_text_unclean.append(extracted_text)\n",
    "    else:\n",
    "        new_text_unclean.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ec54441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings considering complete sentence and use surrounding words for embeddings\n",
    "def extract_embeddings(Posts:list[str],Expression:list[str],Range:int):\n",
    "    embed_dict={i:[] for i in Expression}\n",
    "    for post in Posts:\n",
    "        t=\"[CLS] \"+post+\" [SEP]\"\n",
    "        text_tokenize=tokenizer.tokenize(t)\n",
    "        if len(text_tokenize)<512:\n",
    "            tensor_input_ids=torch.tensor([tokenizer.convert_tokens_to_ids(text_tokenize)])\n",
    "            tensor_segment_ids= torch.tensor([[1]*len(text_tokenize)])\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                outputs=model(tensor_input_ids,tensor_segment_ids)\n",
    "            token_embeddings = torch.squeeze(outputs[0])\n",
    "            for term in Expression:\n",
    "                if term in post:\n",
    "                    sent=extract_context_words_bigram(sentence=post,target_bigram=term,num_words_before=Range,num_words_after=Range)\n",
    "                    for t in sent:\n",
    "                        sent_tokenize=tokenizer.tokenize(t)\n",
    "                        token_index=[index for index,token in enumerate(text_tokenize) if token in sent_tokenize]\n",
    "                        sent_embed=[]\n",
    "                        for index in token_index:\n",
    "                            sent_embed.append(token_embeddings[index])\n",
    "                        if sent_embed:\n",
    "                            embed=torch.mean(torch.stack(sent_embed),dim=0)\n",
    "                            embed_dict[term].append(embed)\n",
    "    return embed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "42dcf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"[CLS] \"+uncleaned_texts[1]+ \" [SEP]\"\n",
    "text_tokenize=tokenizer.tokenize(t)\n",
    "tensor_input_ids=torch.tensor([tokenizer.convert_tokens_to_ids(text_tokenize)])\n",
    "tensor_segment_ids= torch.tensor([[1]*len(text_tokenize)])\n",
    "        \n",
    "with torch.no_grad():\n",
    "    outputs=model(tensor_input_ids,tensor_segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd16119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "impembeddings=extract_embeddings(new_text_lematize,new_terms,Range=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de517056",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_embed_terms=[]\n",
    "for i in impembeddings:\n",
    "    if impembeddings[i]==[]:\n",
    "        no_embed_terms.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "bb4e39f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_embed_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2fbe3520",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cabal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/ReportingLayerData_Bertembeddings.ipynb Cell 72\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dhanushkikkisetti/Documents/Research%20Assistant/Scripts/ReportingLayerData_Bertembeddings.ipynb#Y136sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39mstack((impembeddings[\u001b[39m'\u001b[39;49m\u001b[39mcabal\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cabal'"
     ]
    }
   ],
   "source": [
    "torch.stack((impembeddings['cabal']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1653da",
   "metadata": {},
   "source": [
    "#### To get word embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ae6d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "impterm_embeddings={}\n",
    "for term in new_terms:\n",
    "    if term not in no_embed_terms:\n",
    "        impterm_embeddings[term]=torch.mean(torch.stack(impembeddings[term]),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ba1e0949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['united state', 'goy know', 'blood type', 'vatican ii', 'nostra aetate', 'human right', 'jesus christ', 'far right', 'white people', 'fascist white', 'late 20th', 'space time information', 'white power', 'moon landing', 'middle east', 'critical race', 'church teaching', 'civil right', 'world war', 'old school', 'un special rapporteur', 'federal reserve', 'white men', 'get rid', 'klaus schwab', 'khazarian satanist', 'mel gibson', 'central bank', 'sound like', 'social justice', 'church always taught', 'ruling class', 'go back', 'khazarian mafia', 'white house', 'national socialist', 'destroying nation', 'full disclosure', 'year ago', 'public service', 'white american', 'german people', '20th century', 'white race', 'roy cohn', 'hollywood elite', 'world economic', 'ethnic foids', 'manhattan new york', 'new york city', 'mayer amschel', 'political correctness', 'interest group', 'african identity black', 'frankfurt school', 'coup attempt', 'western civilization', 'catholic church', 'million dollar', 'would say', 'nancy pelosi', 'jeffrey epstein', 'also need', 'grand marshal', 'american lunar', 'crowning achievement', 'took place', 'donald trump', 'financial system', 'intelligence gathering', 'joe biden', 'twin cancer destroying', 'national security', 'social medium', 'air traffic control', 'special military operation', 'mike tyson', 'fema camp', 'dont let', 'queen story time', 'keep getting', 'deep state cabal', 'usa get', 'unborn child', 'color revolution', 'agent embedded', 'end game', 'open society', 'orthodox christian', 'mental illness', 'therefore america', 'rejected christ', 'german christian', 'holy war', 'anti white genocide', 'came across', 'destroy america', 'idiot destroying entire', 'must watch', 'plain sight', 'always going', 'balfour declaration', 'von braun'])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impterm_embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a97379d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_embeddings=extract_embeddings(new_text_unclean,glossary,Range=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2bc5d310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cabal',\n",
       " 'cosmopolitan elite',\n",
       " 'cultural marxism',\n",
       " 'deicide',\n",
       " 'holocough',\n",
       " 'jewish capitalist',\n",
       " 'the goyim know',\n",
       " 'jewish communist',\n",
       " 'jewish lobby',\n",
       " 'new world order',\n",
       " 'rothschild',\n",
       " 'soros',\n",
       " 'zionist',\n",
       " 'zionist occupied government',\n",
       " 'jew down',\n",
       " 'not the real jews']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lematised_glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d33f3bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1325,  0.3495,  0.7495,  ..., -0.2590, -0.0175,  0.0388],\n",
       "        [ 0.2912, -0.1633,  0.5889,  ..., -0.4233,  0.1252,  0.2580],\n",
       "        [ 0.3700,  0.2295,  0.5064,  ..., -0.2986,  0.2346, -0.3927],\n",
       "        ...,\n",
       "        [ 0.6371,  0.2989,  0.6596,  ..., -0.1963, -0.0051,  0.0954],\n",
       "        [ 0.8584,  0.1012,  0.1747,  ..., -0.5123,  0.1665,  0.2528],\n",
       "        [ 0.0639, -0.5284,  0.2625,  ..., -0.5178, -0.2199,  0.1731]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((g_embeddings['cabal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66e41de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_embed_terms=[]\n",
    "for i in g_embeddings:\n",
    "    if g_embeddings[i]==[]:\n",
    "        no_embed_terms.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "92938998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_embed_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b4d77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary_embeddings={}\n",
    "for term in glossary:\n",
    "    if term not in no_embed_terms:\n",
    "        glossary_embeddings[term]=torch.mean(torch.stack(g_embeddings[term]),dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c433d477",
   "metadata": {},
   "source": [
    "#### To get sentence embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "impembeddings,no_embed_terms=extract_embeddings(new_text_lematize,new_terms,rAnge=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "5d8ab4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "impterm_embeddings={}\n",
    "for term in new_terms:\n",
    "    if term not in no_embed_terms:\n",
    "        impterm_embeddings[term]=torch.mean(impembeddings[term],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "id": "66f9fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_embeddings,no_embed_terms=extract_embeddings(new_text_unclean,glossary,rAnge=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "id": "e5958d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary_embeddings={}\n",
    "for term in glossary:\n",
    "    glossary_embeddings[term]=torch.mean(g_embeddings[term],dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5249da",
   "metadata": {},
   "source": [
    "#### similar for both the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c55654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column=[\"Term\"]+glossary+[\"Average\"]\n",
    "bert_similarity_df=pd.DataFrame(columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42cafc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in impterm_embeddings:\n",
    "    score=0\n",
    "    sim_score=[term]\n",
    "    for seed_word in glossary :\n",
    "        s=np.array(torch.cosine_similarity(impterm_embeddings[term].reshape(1,-1),glossary_embeddings[seed_word].reshape(1,-1)))[0]\n",
    "        sim_score.append(s)\n",
    "        score=score+s\n",
    "    sim_score.append(score/len(glossary))\n",
    "    bert_similarity_df.loc[len(bert_similarity_df)]=sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c73b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=bert_similarity_df['Average'].quantile(0.50)\n",
    "bert_similarity_df['predicted']=bert_similarity_df['Average'].apply(lambda x:1 if x>threshold else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f1591e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48371520452201366"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc732d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bert_similarity_df).to_csv('/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/NEWRESULTS_EXTRACTINGTERMS/bertbase_range0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdec41e",
   "metadata": {},
   "source": [
    "## Finetuning the range parameter to check the best performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75d4254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels=imp_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a33c59e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f53ef0",
   "metadata": {},
   "source": [
    "### Fine tuning for word embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "id": "dfb35416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range = 6\n",
      "Range = 7\n",
      "Range = 8\n",
      "Range = 9\n",
      "Range = 10\n",
      "Range = 11\n",
      "Range = 12\n",
      "Range = 13\n",
      "Range = 14\n"
     ]
    }
   ],
   "source": [
    "predicted_labels={}\n",
    "column=[\"Term\"]+glossary+[\"Average\"]\n",
    "for r in range(5,15):\n",
    "    print(\"Range = \"+str(r))\n",
    "    impembeddings=extract_embeddings(new_text_lematize,new_terms,Range=r)\n",
    "    g_embeddings=extract_embeddings(new_text_unclean,glossary,Range=r)\n",
    "    impterm_embeddings={}\n",
    "    for term in new_terms:\n",
    "        impterm_embeddings[term]=torch.mean(torch.stack(impembeddings[term]),dim=0)\n",
    "    glossary_embeddings={}\n",
    "    for term in glossary:\n",
    "        glossary_embeddings[term]=torch.mean(torch.stack(g_embeddings[term]),dim=0)\n",
    "    bert_similarity_df=pd.DataFrame(columns=column)\n",
    "    for term in impterm_embeddings:\n",
    "        score=0\n",
    "        sim_score=[term]\n",
    "        for seed_word in glossary :\n",
    "            s=np.array(torch.cosine_similarity(impterm_embeddings[term].reshape(1,-1),glossary_embeddings[seed_word].reshape(1,-1)))[0]\n",
    "            sim_score.append(s)\n",
    "            score=score+s\n",
    "        sim_score.append(score/len(glossary))\n",
    "        bert_similarity_df.loc[len(bert_similarity_df)]=sim_score\n",
    "    threshold=bert_similarity_df['Average'].quantile(0.50)\n",
    "    bert_similarity_df['predicted']=bert_similarity_df['Average'].apply(lambda x:1 if x>threshold else 0)\n",
    "    predicted_labels[r]=bert_similarity_df['predicted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b05e61",
   "metadata": {},
   "source": [
    "### Fine tuning for sentence embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "ec3eddd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range = 5\n",
      "Range = 6\n",
      "Range = 7\n",
      "Range = 8\n",
      "Range = 9\n",
      "Range = 10\n",
      "Range = 11\n",
      "Range = 12\n",
      "Range = 13\n",
      "Range = 14\n"
     ]
    }
   ],
   "source": [
    "predicted_labels={}\n",
    "column=[\"Term\"]+glossary+[\"Average\"]\n",
    "for r in range(5,15):\n",
    "    print(\"Range = \"+str(r))\n",
    "    impembeddings,no_term_embed=extract_embeddings(new_text_lematize,new_terms,rAnge=r)\n",
    "    g_embeddings,no_term_embed=extract_embeddings(new_text_unclean,glossary,rAnge=r)\n",
    "    impterm_embeddings={}\n",
    "    for term in new_terms:\n",
    "        impterm_embeddings[term]=torch.mean(impembeddings[term],dim=0)\n",
    "    glossary_embeddings={}\n",
    "    for term in glossary:\n",
    "        glossary_embeddings[term]=torch.mean(g_embeddings[term],dim=0)\n",
    "    bert_similarity_df=pd.DataFrame(columns=column)\n",
    "    for term in impterm_embeddings:\n",
    "        score=0\n",
    "        sim_score=[term]\n",
    "        for seed_word in glossary :\n",
    "            s=np.array(torch.cosine_similarity(impterm_embeddings[term].reshape(1,-1),glossary_embeddings[seed_word].reshape(1,-1)))[0]\n",
    "            sim_score.append(s)\n",
    "            score=score+s\n",
    "        sim_score.append(score/len(glossary))\n",
    "        bert_similarity_df.loc[len(bert_similarity_df)]=sim_score\n",
    "    threshold=bert_similarity_df['Average'].quantile(0.50)\n",
    "    bert_similarity_df['predicted']=bert_similarity_df['Average'].apply(lambda x:1 if x>threshold else 0)\n",
    "    predicted_labels[r]=bert_similarity_df['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "id": "fe5d4f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 0     1\n",
       " 1     0\n",
       " 2     1\n",
       " 3     0\n",
       " 4     0\n",
       "      ..\n",
       " 89    0\n",
       " 90    1\n",
       " 91    1\n",
       " 92    0\n",
       " 93    1\n",
       " Name: predicted, Length: 94, dtype: int64,\n",
       " 6: 0     1\n",
       " 1     0\n",
       " 2     1\n",
       " 3     0\n",
       " 4     0\n",
       "      ..\n",
       " 89    0\n",
       " 90    0\n",
       " 91    1\n",
       " 92    0\n",
       " 93    1\n",
       " Name: predicted, Length: 94, dtype: int64,\n",
       " 7: 0     1\n",
       " 1     0\n",
       " 2     1\n",
       " 3     0\n",
       " 4     0\n",
       "      ..\n",
       " 89    0\n",
       " 90    0\n",
       " 91    1\n",
       " 92    0\n",
       " 93    1\n",
       " Name: predicted, Length: 94, dtype: int64,\n",
       " 8: 0     1\n",
       " 1     0\n",
       " 2     1\n",
       " 3     0\n",
       " 4     0\n",
       "      ..\n",
       " 89    0\n",
       " 90    0\n",
       " 91    1\n",
       " 92    0\n",
       " 93    1\n",
       " Name: predicted, Length: 94, dtype: int64,\n",
       " 9: 0     1\n",
       " 1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       "      ..\n",
       " 89    0\n",
       " 90    0\n",
       " 91    1\n",
       " 92    0\n",
       " 93    1\n",
       " Name: predicted, Length: 94, dtype: int64,\n",
       " 10: 0     1\n",
       " 1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       "      ..\n",
       " 89    0\n",
       " 90    0\n",
       " 91    1\n",
       " 92    0\n",
       " 93    1\n",
       " Name: predicted, Length: 94, dtype: int64,\n",
       " 11: 0     1\n",
       " 1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       "      ..\n",
       " 89    0\n",
       " 90    0\n",
       " 91    1\n",
       " 92    0\n",
       " 93    1\n",
       " Name: predicted, Length: 94, dtype: int64,\n",
       " 12: 0     1\n",
       " 1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       "      ..\n",
       " 89    0\n",
       " 90    0\n",
       " 91    1\n",
       " 92    0\n",
       " 93    1\n",
       " Name: predicted, Length: 94, dtype: int64,\n",
       " 13: 0     1\n",
       " 1     1\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       "      ..\n",
       " 89    0\n",
       " 90    0\n",
       " 91    1\n",
       " 92    0\n",
       " 93    1\n",
       " Name: predicted, Length: 94, dtype: int64,\n",
       " 14: 0     1\n",
       " 1     1\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       "      ..\n",
       " 89    0\n",
       " 90    0\n",
       " 91    1\n",
       " 92    0\n",
       " 93    1\n",
       " Name: predicted, Length: 94, dtype: int64}"
      ]
     },
     "execution_count": 1150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "5a468da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance matrix with range of words :  3\n",
      "Accuracy :  0.5873015873015873\n",
      "Precision :  0.5675675675675675\n",
      "Recall  :  0.6774193548387096\n",
      "F1 Score  :  0.6176470588235294\n",
      "Performance matrix with range of words :  4\n",
      "Accuracy :  0.4603174603174603\n",
      "Precision :  0.4594594594594595\n",
      "Recall  :  0.5483870967741935\n",
      "F1 Score  :  0.5\n",
      "Performance matrix with range of words :  5\n",
      "Accuracy :  0.5873015873015873\n",
      "Precision :  0.5675675675675675\n",
      "Recall  :  0.6774193548387096\n",
      "F1 Score  :  0.6176470588235294\n",
      "Performance matrix with range of words :  6\n",
      "Accuracy :  0.6825396825396826\n",
      "Precision :  0.6486486486486487\n",
      "Recall  :  0.7741935483870968\n",
      "F1 Score  :  0.7058823529411764\n",
      "Performance matrix with range of words :  7\n",
      "Accuracy :  0.6190476190476191\n",
      "Precision :  0.5945945945945946\n",
      "Recall  :  0.7096774193548387\n",
      "F1 Score  :  0.6470588235294118\n",
      "Performance matrix with range of words :  8\n",
      "Accuracy :  0.6825396825396826\n",
      "Precision :  0.6486486486486487\n",
      "Recall  :  0.7741935483870968\n",
      "F1 Score  :  0.7058823529411764\n",
      "Performance matrix with range of words :  9\n",
      "Accuracy :  0.7142857142857143\n",
      "Precision :  0.6756756756756757\n",
      "Recall  :  0.8064516129032258\n",
      "F1 Score  :  0.7352941176470588\n",
      "Performance matrix with range of words :  10\n",
      "Accuracy :  0.6190476190476191\n",
      "Precision :  0.5945945945945946\n",
      "Recall  :  0.7096774193548387\n",
      "F1 Score  :  0.6470588235294118\n",
      "Performance matrix with range of words :  11\n",
      "Accuracy :  0.6190476190476191\n",
      "Precision :  0.5945945945945946\n",
      "Recall  :  0.7096774193548387\n",
      "F1 Score  :  0.6470588235294118\n",
      "Performance matrix with range of words :  12\n",
      "Accuracy :  0.6507936507936508\n",
      "Precision :  0.6216216216216216\n",
      "Recall  :  0.7419354838709677\n",
      "F1 Score  :  0.676470588235294\n"
     ]
    }
   ],
   "source": [
    "for r in range(3,13):\n",
    "    print(\"Performance matrix with range of words :  \"+ str(r))\n",
    "    print(\"Accuracy : \",accuracy_score(predicted_labels[r],actual_labels))\n",
    "    print(\"Precision : \",precision_score(predicted_labels[r],actual_labels))\n",
    "    print(\"Recall  : \",recall_score(predicted_labels[r],actual_labels))\n",
    "    print(\"F1 Score  : \",f1_score(predicted_labels[r],actual_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "id": "fc09c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame.from_dict(predicted_labels)\n",
    "results['avg']=results.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "id": "d8526129",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Predicted']=results['avg'].apply(lambda x:1 if x>0.8 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "4b8628c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "     ..\n",
       "89    0\n",
       "90    0\n",
       "91    1\n",
       "92    0\n",
       "93    0\n",
       "Name: Predicted, Length: 94, dtype: int64"
      ]
     },
     "execution_count": 969,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "id": "66b387b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/Final fine tune bert word embed/finetune_range_r_parameter_lematize5_15.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c15f2bd",
   "metadata": {},
   "source": [
    "### Checking with antisemetic terms definations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cc630873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term or Phrase</th>\n",
       "      <th>Regular Definition</th>\n",
       "      <th>Antisemitic Definition</th>\n",
       "      <th>Related Terms</th>\n",
       "      <th>Direct or Indirect</th>\n",
       "      <th>Antisemitic Trope</th>\n",
       "      <th>Emerging Term (Y/N)</th>\n",
       "      <th>Emerging Trope (Y/N)</th>\n",
       "      <th>Extremism Rank</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Means of Discovery</th>\n",
       "      <th>Discovery Date/Time (Emerging Only)</th>\n",
       "      <th>Sources</th>\n",
       "      <th>Source Link</th>\n",
       "      <th>Social Media Site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blood libel</td>\n",
       "      <td>perpetuated accusation that Jews have murdered...</td>\n",
       "      <td>The blood libel charge—also known as the ritua...</td>\n",
       "      <td>Blood thirsty,</td>\n",
       "      <td>Indirect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Canadian metal group is called \"Blood Libel\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Jewish Committee</td>\n",
       "      <td>Page 4: https://www.ajc.org/sites/default/file...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cabal</td>\n",
       "      <td>a small, powerful group that seeks to establis...</td>\n",
       "      <td>Jews have long been accused of being part of a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indirect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Jewish Committee</td>\n",
       "      <td>Page 4: https://www.ajc.org/sites/default/file...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clannish</td>\n",
       "      <td>of or relating to a clan; tending to associate...</td>\n",
       "      <td>Referring to Jews as clannish is an antisemiti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indirect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Jewish Committee</td>\n",
       "      <td>Page 5: https://www.ajc.org/sites/default/file...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conspiracy theory</td>\n",
       "      <td>a belief that some covert but influential orga...</td>\n",
       "      <td>From medieval times until the present day, con...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Direct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Jewish Committee</td>\n",
       "      <td>Page 5 and 6: https://www.ajc.org/sites/defaul...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>power or authority to guide or manage</td>\n",
       "      <td>False reports that claim Jews control the medi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indirect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Jewish Committee</td>\n",
       "      <td>Page 6: https://www.ajc.org/sites/default/file...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Term or Phrase                                 Regular Definition  \\\n",
       "0       Blood libel   perpetuated accusation that Jews have murdered...   \n",
       "1              Cabal  a small, powerful group that seeks to establis...   \n",
       "2           Clannish  of or relating to a clan; tending to associate...   \n",
       "3  Conspiracy theory  a belief that some covert but influential orga...   \n",
       "4            Control              power or authority to guide or manage   \n",
       "\n",
       "                              Antisemitic Definition    Related Terms  \\\n",
       "0  The blood libel charge—also known as the ritua...  Blood thirsty,    \n",
       "1  Jews have long been accused of being part of a...              NaN   \n",
       "2  Referring to Jews as clannish is an antisemiti...              NaN   \n",
       "3  From medieval times until the present day, con...              NaN   \n",
       "4  False reports that claim Jews control the medi...              NaN   \n",
       "\n",
       "  Direct or Indirect  Antisemitic Trope Emerging Term (Y/N)  \\\n",
       "0           Indirect                NaN                  No   \n",
       "1           Indirect                NaN        Undetermined   \n",
       "2           Indirect                NaN                  No   \n",
       "3             Direct                NaN                 Yes   \n",
       "4           Indirect                NaN        Undetermined   \n",
       "\n",
       "   Emerging Trope (Y/N)  Extremism Rank  \\\n",
       "0                   NaN             NaN   \n",
       "1                   NaN             NaN   \n",
       "2                   NaN             NaN   \n",
       "3                   NaN             NaN   \n",
       "4                   NaN             NaN   \n",
       "\n",
       "                                               Notes Means of Discovery  \\\n",
       "0  A Canadian metal group is called \"Blood Libel\"...                NaN   \n",
       "1                                                NaN                NaN   \n",
       "2                                                NaN                NaN   \n",
       "3                                                NaN                NaN   \n",
       "4                                                NaN                NaN   \n",
       "\n",
       "   Discovery Date/Time (Emerging Only)                    Sources  \\\n",
       "0                                  NaN  American Jewish Committee   \n",
       "1                                  NaN  American Jewish Committee   \n",
       "2                                  NaN  American Jewish Committee   \n",
       "3                                  NaN  American Jewish Committee   \n",
       "4                                  NaN  American Jewish Committee   \n",
       "\n",
       "                                         Source Link  Social Media Site  \n",
       "0  Page 4: https://www.ajc.org/sites/default/file...                NaN  \n",
       "1  Page 4: https://www.ajc.org/sites/default/file...                NaN  \n",
       "2  Page 5: https://www.ajc.org/sites/default/file...                NaN  \n",
       "3  Page 5 and 6: https://www.ajc.org/sites/defaul...                NaN  \n",
       "4  Page 6: https://www.ajc.org/sites/default/file...                NaN  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_definition_df=pd.read_csv(\"Antisemetism_term_definition.csv\")\n",
    "terms_definition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "98cabc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_definition_df=terms_definition_df[terms_definition_df[\"Term or Phrase\"].apply(lambda x:True if x.lower() in glossary else False)==True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "608047d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                                 Cabal\n",
       "5                    Cosmopolitan elite\n",
       "8                      Cultural Marxism\n",
       "10                              Deicide\n",
       "15                     “The Goyim Know”\n",
       "17                            Holocough\n",
       "20                    Jewish capitalist\n",
       "21                     Jewish communist\n",
       "26                         Jewish lobby\n",
       "30                      New World Order\n",
       "31                  \"not the real Jews\"\n",
       "35                           Rothschild\n",
       "41                                Soros\n",
       "43                      Zionist / “Zio”\n",
       "44    Zionist Occupied Government (ZOG)\n",
       "Name: Term or Phrase, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_definition_df['Term or Phrase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e62819b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "antisemetic_definition={}\n",
    "for i in range(len(terms_definition_df)):\n",
    "    antisemetic_definition[terms_definition_df['Term or Phrase'].iloc[i]]=terms_definition_df['Antisemitic Definition'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "515feac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "antisemetic_definition_embeddings={}\n",
    "for term in antisemetic_definition:\n",
    "    tokens=tokenizer(antisemetic_definition[term],return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output=model(**tokens)\n",
    "    antisemetic_definition_embeddings[term.lower()]=output['pooler_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "85b309b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "column=[\"Term\"]+glossary+[\"Average\"]\n",
    "bert_similarity_df=pd.DataFrame(columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7ce726a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in impterm_embeddings:\n",
    "    score=0\n",
    "    sim_score=[term]\n",
    "    for seed_word in glossary :\n",
    "        s=np.array(torch.cosine_similarity(impterm_embeddings[term].reshape(1,-1),antisemetic_definition_embeddings[seed_word].reshape(1,-1)))[0]\n",
    "        sim_score.append(s)\n",
    "        score=score+s\n",
    "    sim_score.append(score/len(glossary))\n",
    "    bert_similarity_df.loc[len(bert_similarity_df)]=sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2487f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=sum(bert_similarity_df.Average)/len(bert_similarity_df)\n",
    "bert_similarity_df['predicted']=bert_similarity_df['Average'].apply(lambda x:1 if x>threshold else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bc2f75b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8104986549226525"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "51a9f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bert_similarity_df).to_csv('Raza_bigrams_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cc0ae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Term     cabal  cosmopolitan elite  \\\n",
      "0             frankfurt school  0.989069            0.989927   \n",
      "1              critical theory  0.981373            0.989109   \n",
      "2                  world order  0.998177            0.987921   \n",
      "3            conspiracy theory  0.990634            0.991050   \n",
      "4                    new world  0.998318            0.986168   \n",
      "5                 united state  0.997652            0.980121   \n",
      "6             cultural marxist  0.979573            0.988594   \n",
      "7                critical race  0.980110            0.988045   \n",
      "8                  race theory  0.985699            0.989968   \n",
      "9         critical race theory  0.981106            0.989057   \n",
      "10       political correctness  0.980166            0.988972   \n",
      "11              thierry baudet  0.980898            0.981127   \n",
      "12              social justice  0.983762            0.989501   \n",
      "13                  deep state  0.998774            0.986023   \n",
      "14            marxism cultural  0.943070            0.971075   \n",
      "15                white people  0.968191            0.985597   \n",
      "16            dutch parliament  0.987643            0.985148   \n",
      "17              speech thierry  0.982780            0.959697   \n",
      "18       speech thierry baudet  0.984554            0.965700   \n",
      "19              marxism agenda  0.980559            0.988736   \n",
      "20     cultural marxism agenda  0.974819            0.988141   \n",
      "21                    new york  0.987340            0.954843   \n",
      "22                soviet union  0.989524            0.991883   \n",
      "23                  th century  0.993050            0.989103   \n",
      "24               term cultural  0.980682            0.988077   \n",
      "25    marxism cultural marxism  0.935755            0.965751   \n",
      "26             khazarian mafia  0.978044            0.989998   \n",
      "27                 golden dawn  0.997584            0.987257   \n",
      "28   cultural marxism cultural  0.924109            0.958700   \n",
      "29                 culture war  0.984011            0.992838   \n",
      "30           marxism frankfurt  0.977219            0.984954   \n",
      "31                young people  0.977818            0.986095   \n",
      "32             western culture  0.990775            0.991186   \n",
      "33  cultural marxism frankfurt  0.984039            0.985741   \n",
      "34                 human right  0.988651            0.989973   \n",
      "35       term cultural marxism  0.973559            0.985419   \n",
      "36                   last year  0.993604            0.988141   \n",
      "37          communism cultural  0.934925            0.963743   \n",
      "38    marxism frankfurt school  0.974518            0.985271   \n",
      "39                  white race  0.994752            0.975651   \n",
      "40  communism cultural marxism  0.942790            0.970361   \n",
      "41                adolf hitler  0.991073            0.990497   \n",
      "42                george soros  0.995687            0.984569   \n",
      "43                 great reset  0.997441            0.990178   \n",
      "44                   black eye  0.991719            0.981154   \n",
      "45                   civil war  0.995688            0.991037   \n",
      "46           identity politics  0.970953            0.984004   \n",
      "47             western society  0.975787            0.990519   \n",
      "48                   world war  0.985289            0.991943   \n",
      "49             school cultural  0.968735            0.985417   \n",
      "50             theory cultural  0.960451            0.980818   \n",
      "51              secret history  0.957347            0.979220   \n",
      "52        western civilization  0.983212            0.992746   \n",
      "53             zionist partner  0.942704            0.971123   \n",
      "54            order illuminati  0.976778            0.985203   \n",
      "55           shadow government  0.998199            0.984815   \n",
      "56           mainstream medium  0.990320            0.989394   \n",
      "57                    need new  0.983787            0.971841   \n",
      "58             theory critical  0.988950            0.983125   \n",
      "59        bolshevik revolution  0.973482            0.988492   \n",
      "60         cultural bolshevism  0.976093            0.988385   \n",
      "61                useful idiot  0.995820            0.987364   \n",
      "62                    year old  0.988989            0.966449   \n",
      "63                   dont want  0.967422            0.980770   \n",
      "64     theory cultural marxism  0.958390            0.979863   \n",
      "65       military intelligence  0.994326            0.973488   \n",
      "\n",
      "    cultural marxism   deicide  holocough  jewish capitalist  \\\n",
      "0           0.995571  0.993378   0.984841           0.995911   \n",
      "1           0.998554  0.994669   0.975336           0.995360   \n",
      "2           0.981349  0.983271   0.994994           0.988485   \n",
      "3           0.993280  0.993225   0.986877           0.996056   \n",
      "4           0.978765  0.981259   0.995918           0.986796   \n",
      "5           0.971830  0.975367   0.995595           0.983386   \n",
      "6           0.999290  0.996562   0.973413           0.995400   \n",
      "7           0.998758  0.994821   0.974242           0.994674   \n",
      "8           0.997630  0.994856   0.980415           0.996359   \n",
      "9           0.998910  0.995346   0.975044           0.995443   \n",
      "10          0.998742  0.995041   0.973320           0.995265   \n",
      "11          0.987639  0.986620   0.978259           0.988518   \n",
      "12          0.997952  0.994682   0.977613           0.994765   \n",
      "13          0.979608  0.982036   0.995706           0.987829   \n",
      "14          0.989947  0.984903   0.933550           0.977260   \n",
      "15          0.996639  0.996257   0.960778           0.990545   \n",
      "16          0.980933  0.981569   0.984256           0.985412   \n",
      "17          0.959776  0.961900   0.984678           0.972399   \n",
      "18          0.967378  0.968685   0.985488           0.977391   \n",
      "19          0.997013  0.993530   0.974263           0.991777   \n",
      "20          0.996932  0.992947   0.967505           0.989812   \n",
      "21          0.941221  0.947712   0.990102           0.958919   \n",
      "22          0.995537  0.995636   0.985080           0.995754   \n",
      "23          0.990361  0.990065   0.989959           0.993576   \n",
      "24          0.995850  0.993644   0.975975           0.994721   \n",
      "25          0.987276  0.981146   0.926087           0.972369   \n",
      "26          0.994416  0.993585   0.972250           0.989665   \n",
      "27          0.978944  0.982135   0.994049           0.985754   \n",
      "28          0.982136  0.975440   0.913409           0.964629   \n",
      "29          0.997670  0.995128   0.977249           0.995948   \n",
      "30          0.995956  0.991641   0.971697           0.991068   \n",
      "31          0.994868  0.993238   0.973291           0.993195   \n",
      "32          0.994088  0.993226   0.987301           0.995057   \n",
      "33          0.994785  0.991831   0.979818           0.993302   \n",
      "34          0.994574  0.994190   0.983809           0.994833   \n",
      "35          0.996550  0.993012   0.967937           0.992357   \n",
      "36          0.990035  0.991439   0.991057           0.993349   \n",
      "37          0.986116  0.981042   0.925446           0.970585   \n",
      "38          0.996182  0.992881   0.969155           0.991474   \n",
      "39          0.967789  0.972141   0.992649           0.981739   \n",
      "40          0.989600  0.985557   0.933516           0.976542   \n",
      "41          0.991452  0.992566   0.986277           0.994427   \n",
      "42          0.982241  0.983980   0.993850           0.990343   \n",
      "43          0.986700  0.989268   0.995183           0.993192   \n",
      "44          0.976828  0.977004   0.988690           0.982068   \n",
      "45          0.989823  0.992319   0.991848           0.994845   \n",
      "46          0.998636  0.993253   0.963837           0.991690   \n",
      "47          0.998055  0.994521   0.967179           0.993374   \n",
      "48          0.997171  0.995784   0.979725           0.994978   \n",
      "49          0.997276  0.991615   0.961921           0.989104   \n",
      "50          0.996984  0.991293   0.952676           0.986412   \n",
      "51          0.990649  0.987399   0.949637           0.978884   \n",
      "52          0.998041  0.997314   0.976786           0.995321   \n",
      "53          0.986615  0.984755   0.934671           0.972623   \n",
      "54          0.984214  0.981404   0.971241           0.981671   \n",
      "55          0.973002  0.979043   0.994963           0.984251   \n",
      "56          0.994911  0.993524   0.986136           0.995015   \n",
      "57          0.970815  0.968897   0.981625           0.979102   \n",
      "58          0.983609  0.984334   0.985584           0.990315   \n",
      "59          0.996633  0.993594   0.966514           0.990008   \n",
      "60          0.998742  0.995694   0.969551           0.993940   \n",
      "61          0.983740  0.985162   0.993621           0.990528   \n",
      "62          0.949847  0.956327   0.990348           0.966966   \n",
      "63          0.994783  0.992051   0.962564           0.986944   \n",
      "64          0.996353  0.990679   0.950392           0.985217   \n",
      "65          0.962813  0.964831   0.992091           0.974199   \n",
      "\n",
      "    jewish communist  jewish lobby  new world order  rothschild   Average  \\\n",
      "0           0.996810      0.993741         0.993355    0.995499  0.992810   \n",
      "1           0.992461      0.988093         0.987036    0.990749  0.989274   \n",
      "2           0.996124      0.995788         0.999867    0.996587  0.992256   \n",
      "3           0.995691      0.993476         0.992631    0.993218  0.992614   \n",
      "4           0.995401      0.995157         0.999721    0.995840  0.991334   \n",
      "5           0.992329      0.995104         0.996546    0.992756  0.988069   \n",
      "6           0.991817      0.986334         0.984185    0.989268  0.988444   \n",
      "7           0.991688      0.987437         0.985994    0.990018  0.988579   \n",
      "8           0.994460      0.991272         0.990055    0.992623  0.991334   \n",
      "9           0.992130      0.987990         0.986438    0.990274  0.989174   \n",
      "10          0.991557      0.987174         0.985774    0.989776  0.988579   \n",
      "11          0.989942      0.987255         0.984260    0.990035  0.985455   \n",
      "12          0.993534      0.989990         0.989231    0.992551  0.990358   \n",
      "13          0.995375      0.995569         0.998797    0.995138  0.991485   \n",
      "14          0.965320      0.957076         0.951653    0.963934  0.963779   \n",
      "15          0.984007      0.976610         0.973235    0.980737  0.981260   \n",
      "16          0.989759      0.988175         0.989171    0.989872  0.986194   \n",
      "17          0.980697      0.984636         0.981059    0.981945  0.974957   \n",
      "18          0.984793      0.987542         0.984148    0.986038  0.979172   \n",
      "19          0.992261      0.987050         0.987324    0.991836  0.988435   \n",
      "20          0.988509      0.981630         0.982515    0.987807  0.985062   \n",
      "21          0.975505      0.980754         0.983557    0.975993  0.969595   \n",
      "22          0.997994      0.993740         0.993414    0.996305  0.993487   \n",
      "23          0.996781      0.994519         0.995619    0.996224  0.992926   \n",
      "24          0.990321      0.986212         0.983761    0.986933  0.987618   \n",
      "25          0.960044      0.951297         0.945389    0.958765  0.958388   \n",
      "26          0.989594      0.983730         0.984107    0.990351  0.986574   \n",
      "27          0.994296      0.992963         0.998009    0.995177  0.990617   \n",
      "28          0.950160      0.938986         0.934500    0.947546  0.948962   \n",
      "29          0.992739      0.989004         0.988562    0.991456  0.990461   \n",
      "30          0.990251      0.986158         0.985340    0.990409  0.986469   \n",
      "31          0.989572      0.985568         0.982434    0.987752  0.986383   \n",
      "32          0.997215      0.993060         0.993784    0.994607  0.993030   \n",
      "33          0.993931      0.992211         0.990332    0.994378  0.990037   \n",
      "34          0.995921      0.993944         0.991924    0.995111  0.992293   \n",
      "35          0.986022      0.980313         0.977700    0.981756  0.983462   \n",
      "36          0.997050      0.994796         0.995289    0.995164  0.992992   \n",
      "37          0.960252      0.950201         0.944940    0.958685  0.957593   \n",
      "38          0.988686      0.984710         0.982311    0.989056  0.985424   \n",
      "39          0.989610      0.991448         0.992997    0.987552  0.984633   \n",
      "40          0.966126      0.956251         0.951516    0.963989  0.963625   \n",
      "41          0.997809      0.995562         0.994837    0.997803  0.993230   \n",
      "42          0.996270      0.998032         0.997199    0.997440  0.991961   \n",
      "43          0.997536      0.996074         0.997797    0.996264  0.993963   \n",
      "44          0.990222      0.990405         0.995445    0.991650  0.986518   \n",
      "45          0.998408      0.997150         0.996867    0.997359  0.994534   \n",
      "46          0.986076      0.980644         0.978412    0.984359  0.983186   \n",
      "47          0.988278      0.982942         0.981681    0.987132  0.985947   \n",
      "48          0.995590      0.990113         0.990327    0.994239  0.991516   \n",
      "49          0.984610      0.976663         0.976477    0.982419  0.981424   \n",
      "50          0.979584      0.971946         0.969048    0.977478  0.976669   \n",
      "51          0.974813      0.965752         0.966742    0.975539  0.972598   \n",
      "52          0.993737      0.987663         0.987862    0.991706  0.990439   \n",
      "53          0.964740      0.952426         0.950677    0.962337  0.962267   \n",
      "54          0.983936      0.980848         0.985056    0.986562  0.981691   \n",
      "55          0.991116      0.992014         0.994937    0.990616  0.988296   \n",
      "56          0.996617      0.994438         0.994094    0.995645  0.993009   \n",
      "57          0.984282      0.985930         0.987311    0.983816  0.979741   \n",
      "58          0.990231      0.989723         0.989289    0.987934  0.987309   \n",
      "59          0.987961      0.980965         0.981061    0.987649  0.984636   \n",
      "60          0.989794      0.984684         0.981775    0.988197  0.986686   \n",
      "61          0.994949      0.992942         0.996358    0.992589  0.991307   \n",
      "62          0.977705      0.982305         0.984498    0.977012  0.974045   \n",
      "63          0.983378      0.974888         0.974231    0.979227  0.979626   \n",
      "64          0.977922      0.969975         0.967076    0.975715  0.975158   \n",
      "65          0.985638      0.988657         0.993481    0.987415  0.981694   \n",
      "\n",
      "    predicted  \n",
      "0           1  \n",
      "1           1  \n",
      "2           1  \n",
      "3           1  \n",
      "4           1  \n",
      "5           1  \n",
      "6           1  \n",
      "7           1  \n",
      "8           1  \n",
      "9           1  \n",
      "10          1  \n",
      "11          1  \n",
      "12          1  \n",
      "13          1  \n",
      "14          0  \n",
      "15          0  \n",
      "16          1  \n",
      "17          0  \n",
      "18          0  \n",
      "19          1  \n",
      "20          1  \n",
      "21          0  \n",
      "22          1  \n",
      "23          1  \n",
      "24          1  \n",
      "25          0  \n",
      "26          1  \n",
      "27          1  \n",
      "28          0  \n",
      "29          1  \n",
      "30          1  \n",
      "31          1  \n",
      "32          1  \n",
      "33          1  \n",
      "34          1  \n",
      "35          0  \n",
      "36          1  \n",
      "37          0  \n",
      "38          1  \n",
      "39          1  \n",
      "40          0  \n",
      "41          1  \n",
      "42          1  \n",
      "43          1  \n",
      "44          1  \n",
      "45          1  \n",
      "46          0  \n",
      "47          1  \n",
      "48          1  \n",
      "49          0  \n",
      "50          0  \n",
      "51          0  \n",
      "52          1  \n",
      "53          0  \n",
      "54          0  \n",
      "55          1  \n",
      "56          1  \n",
      "57          0  \n",
      "58          1  \n",
      "59          1  \n",
      "60          1  \n",
      "61          1  \n",
      "62          0  \n",
      "63          0  \n",
      "64          0  \n",
      "65          0  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(bert_similarity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f46ca3",
   "metadata": {},
   "source": [
    "## Classification of 4 Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30732ef",
   "metadata": {},
   "source": [
    "##### Finetune bert+ word embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e51c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=pd.read_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/Final fine tune bert word embed/finetune_range_r_parameter_lematize1_10.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "id": "56d890c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     1\n",
       "2     1\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "89    0\n",
       "90    0\n",
       "91    0\n",
       "92    0\n",
       "93    0\n",
       "Name: Actual, Length: 94, dtype: int64"
      ]
     },
     "execution_count": 1158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file.Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11971b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for : Finetune bert+ word embed\n",
      "-----------------------------------------\n",
      "Accuracy :  0.7978723404255319\n",
      "Precision :  0.631578947368421\n",
      "Recall  :  0.8275862068965517\n",
      "F1 Score  :  0.716417910447761\n"
     ]
    }
   ],
   "source": [
    "### 1 using Bert model to extract embedding using tokens to compare similarity between imp terms and glossary\n",
    "#data_file=pd.read_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/1.csv\",encoding='latin-1')\n",
    "print(\"Results for : Finetune bert+ word embed\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Accuracy : \",accuracy_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"Precision : \",precision_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"Recall  : \",recall_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"F1 Score  : \",f1_score(data_file['Actual'],data_file['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "id": "a19f74d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51, 14],\n",
       "       [ 5, 24]])"
      ]
     },
     "execution_count": 1178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(data_file['Actual'],data_file['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e835d0",
   "metadata": {},
   "source": [
    "##### Bert model + word embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccf98b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=pd.read_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/Final fine tune bert sentence embed/finetune_range_r_parameter_lematize5_15.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "b2227c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for : bert model + word embed\n",
      "-----------------------------------------\n",
      "Accuracy :  0.6914893617021277\n",
      "Precision :  0.6896551724137931\n",
      "Recall  :  0.5\n",
      "F1 Score  :  0.5797101449275363\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for : bert model + word embed\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Accuracy : \",accuracy_score(data_file['Predicted'],data_file['Actual']))\n",
    "print(\"Precision : \",precision_score(data_file['Predicted'],data_file['Actual']))\n",
    "print(\"Recall  : \",recall_score(data_file['Predicted'],data_file['Actual']))\n",
    "print(\"F1 Score  : \",f1_score(data_file['Predicted'],data_file['Actual']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "id": "40040273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47, 18],\n",
       "       [13, 16]])"
      ]
     },
     "execution_count": 1171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(data_file['Actual'],data_file['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5fddad",
   "metadata": {},
   "source": [
    "##### Fine tune bert model + sentence embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c49c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=pd.read_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/DSAA 2024/Solution 2-1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324bce5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for : Fine tune bert model + sentence embed\n",
      "-----------------------------------------\n",
      "Accuracy :  0.6808510638297872\n",
      "Precision :  0.4857142857142857\n",
      "Recall  :  0.5862068965517241\n",
      "F1 Score  :  0.53125\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for : Fine tune bert model + sentence embed\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Accuracy : \",accuracy_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"Precision : \",precision_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"Recall  : \",recall_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"F1 Score  : \",f1_score(data_file['Actual'],data_file['Predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f6edcc",
   "metadata": {},
   "source": [
    "##### Bert model + Sentence embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49e6074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=pd.read_csv(\"/Users/dhanushkikkisetti/Documents/Research Assistant/Scripts/baseline_sentence_embed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3237725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for : Fine tune bert model + sentence embed\n",
      "-----------------------------------------\n",
      "Accuracy :  0.8076923076923077\n",
      "Precision :  0.38461538461538464\n",
      "Recall  :  0.7142857142857143\n",
      "F1 Score  :  0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for : Fine tune bert model + sentence embed\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Accuracy : \",accuracy_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"Precision : \",precision_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"Recall  : \",recall_score(data_file['Actual'],data_file['Predicted']))\n",
    "print(\"F1 Score  : \",f1_score(data_file['Actual'],data_file['Predicted']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
